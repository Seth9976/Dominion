// 函数: _ZNK5Botan7Noekeon14simd_encrypt_4EPKhPh
// 地址: 0xdccf68
// 来自: E:\torrent\Cursor\Dominion_1.0.3315\split_config.arm64_v8a\lib\arm64-v8a\libTGGAndroid.so

int32_t* x9 = *(arg1 + 8)
int64_t i = 0
int32_t temp0 = *x9
int128_t v0
v0.d = temp0
v0:4.d = temp0
v0:8.d = temp0
v0:0xc.d = temp0
uint128_t v5 = *(arg2 + 0x10)
uint128_t v6 = *(arg2 + 0x20)
uint128_t v7 = *(arg2 + 0x30)
int32_t temp0_1 = x9[2]
int128_t v2
v2.d = temp0_1
v2:4.d = temp0_1
v2:8.d = temp0_1
v2:0xc.d = temp0_1
int32_t temp0_2 = *x9
int128_t v3
v3.d = temp0_2
v3:4.d = temp0_2
v3:8.d = temp0_2
v3:0xc.d = temp0_2
int32_t temp0_3 = x9[3]
int128_t v1
v1.d = temp0_3
v1:4.d = temp0_3
v1:8.d = temp0_3
v1:0xc.d = temp0_3
uint128_t v4_1 = vrev32q_s8(*arg2)
uint128_t v5_1 = vrev32q_s8(v5)
uint128_t v6_1 = vrev32q_s8(v6)
uint128_t v7_1 = vrev32q_s8(v7)
uint128_t v16 = vzip1q_s32(v4_1, v6_1)
uint128_t v6_2 = vzip2q_s32(v4_1, v6_1)
uint128_t v4_2 = vzip1q_s32(v5_1, v7_1)
uint128_t v17 = vzip2q_s32(v5_1, v7_1)
uint128_t v5_2 = vzip1q_s32(v16, v4_2)
uint128_t v7_2 = vzip2q_s32(v16, v4_2)
uint128_t v4_3 = vzip1q_s32(v6_2, v17)
uint128_t v6_3 = vzip2q_s32(v6_2, v17)
uint128_t v18
uint128_t v19

do
    uint32_t x10_1 = zx.d(*(Botan::Noekeon::RC + i))
    int128_t v7_3 = v7_2 ^ v3
    uint128_t v6_4 = v6_3 ^ v1
    int128_t v16_1 = v6_4 ^ v7_3
    v17.d = v16_1.d u>> 0x18
    v17:4.d = v16_1:4.d u>> 0x18
    v17:8.d = v16_1:8.d u>> 0x18
    v17:0xc.d = v16_1:0xc.d u>> 0x18
    v18.d = v16_1.d << 8
    v18:4.d = v16_1:4.d << 8
    v18:8.d = v16_1:8.d << 8
    v18:0xc.d = v16_1:0xc.d << 8
    uint128_t v17_1 = vorrq_s8(v18, v17)
    v19.d = v16_1.d u>> 8
    v19:4.d = v16_1:4.d u>> 8
    v19:8.d = v16_1:8.d u>> 8
    v19:0xc.d = v16_1:0xc.d u>> 8
    v18.d = v16_1.d << 0x18
    v18:4.d = v16_1:4.d << 0x18
    v18:8.d = v16_1:8.d << 0x18
    v18:0xc.d = v16_1:0xc.d << 0x18
    int128_t v16_2 = v17_1 ^ v16_1
    v17_1.d = x10_1
    v17_1:4.d = x10_1
    v17_1:8.d = x10_1
    v17_1:0xc.d = x10_1
    uint128_t v5_3 = v17_1 ^ v5_2
    uint128_t v16_3 = v16_2 ^ vorrq_s8(v18, v19)
    uint128_t v4_4 = v5_3 ^ v4_3
    uint128_t v17_2 = v4_3 ^ v2 ^ v16_3
    uint128_t v18_1
    v18_1.d = v4_4.d u>> 0x18
    v18_1:4.d = v4_4:4.d u>> 0x18
    v18_1:8.d = v4_4:8.d u>> 0x18
    v18_1:0xc.d = v4_4:0xc.d u>> 0x18
    v19.d = v4_4.d << 8
    v19:4.d = v4_4:4.d << 8
    v19:8.d = v4_4:8.d << 8
    v19:0xc.d = v4_4:0xc.d << 8
    int128_t v5_5 = v5_3 ^ v0 ^ v16_3
    v16_3.d = v4_4.d u>> 8
    v16_3:4.d = v4_4:4.d u>> 8
    v16_3:8.d = v4_4:8.d u>> 8
    v16_3:0xc.d = v4_4:0xc.d u>> 8
    v18 = vorrq_s8(v19, v18_1)
    v19.d = v4_4.d << 0x18
    v19:4.d = v4_4:4.d << 0x18
    v19:8.d = v4_4:8.d << 0x18
    v19:0xc.d = v4_4:0xc.d << 0x18
    uint128_t v4_6 = v18 ^ v4_4 ^ vorrq_s8(v19, v16_3)
    uint128_t v7_4 = v7_3 ^ v4_6
    uint128_t v4_7 = v6_4 ^ v4_6
    v19.d = v17_2.d u>> 0x1b
    v19:4.d = v17_2:4.d u>> 0x1b
    v19:8.d = v17_2:8.d u>> 0x1b
    v19:0xc.d = v17_2:0xc.d u>> 0x1b
    v17_2.d <<= 5
    v17_2:4.d <<= 5
    v17_2:8.d <<= 5
    v17_2:0xc.d <<= 5
    v6_4.d = v7_4.d u>> 0x1f
    v6_4:4.d = v7_4:4.d u>> 0x1f
    v6_4:8.d = v7_4:8.d u>> 0x1f
    v6_4:0xc.d = v7_4:0xc.d u>> 0x1f
    v7_4.d <<= 1
    v7_4:4.d <<= 1
    v7_4:8.d <<= 1
    v7_4:0xc.d <<= 1
    uint128_t v16_4
    v16_4.d = v4_7.d u>> 0x1e
    v16_4:4.d = v4_7:4.d u>> 0x1e
    v16_4:8.d = v4_7:8.d u>> 0x1e
    v16_4:0xc.d = v4_7:0xc.d u>> 0x1e
    v4_7.d <<= 2
    v4_7:4.d <<= 2
    v4_7:8.d <<= 2
    v4_7:0xc.d <<= 2
    uint128_t v17_3 = vorrq_s8(v17_2, v19)
    uint128_t v6_5 = vorrq_s8(v7_4, v6_4)
    uint128_t v7_5 = vorrq_s8(v4_7, v16_4)
    uint128_t v4_9 = vorrq_s8(v17_3, v7_5) ^ v6_5
    uint128_t v5_6 = v5_5 ^ (v17_3 & not.o(v4_9))
    uint128_t v6_7 = v17_3 ^ v7_5 ^ not.o(v4_9)
    uint128_t v16_6 = v6_7 ^ v5_6
    uint128_t v4_10 = vorrq_s8(v6_7, v5_6) ^ v4_9
    i += 1
    v17.d = v5_6.d u>> 2
    v17:4.d = v5_6:4.d u>> 2
    v17:8.d = v5_6:8.d u>> 2
    v17:0xc.d = v5_6:0xc.d u>> 2
    v18.d = v5_6.d << 0x1e
    v18:4.d = v5_6:4.d << 0x1e
    v18:8.d = v5_6:8.d << 0x1e
    v18:0xc.d = v5_6:0xc.d << 0x1e
    v5_6.d = v16_6.d u>> 5
    v5_6:4.d = v16_6:4.d u>> 5
    v5_6:8.d = v16_6:8.d u>> 5
    v5_6:0xc.d = v16_6:0xc.d u>> 5
    uint128_t v6_8
    v6_8.d = v16_6.d << 0x1b
    v6_8:4.d = v16_6:4.d << 0x1b
    v6_8:8.d = v16_6:8.d << 0x1b
    v6_8:0xc.d = v16_6:0xc.d << 0x1b
    v19.d = v4_10.d u>> 1
    v19:4.d = v4_10:4.d u>> 1
    v19:8.d = v4_10:8.d u>> 1
    v19:0xc.d = v4_10:0xc.d u>> 1
    uint128_t v20
    v20.d = v4_10.d << 0x1f
    v20:4.d = v4_10:4.d << 0x1f
    v20:8.d = v4_10:8.d << 0x1f
    v20:0xc.d = v4_10:0xc.d << 0x1f
    v4_3 = vorrq_s8(v6_8, v5_6)
    v5_2 = (v4_10 & v16_6) ^ v7_5
    v7_2 = vorrq_s8(v20, v19)
    v6_3 = vorrq_s8(v18, v17)
while (i != 0x10)

uint128_t v16_7
v16_7.d = 0xd4
v16_7:4.d = 0xd4
v16_7:8.d = 0xd4
v16_7:0xc.d = 0xd4
int128_t v3_1 = v7_2 ^ v3
int128_t v1_1 = v6_3 ^ v1
uint128_t v5_7 = v5_2 ^ v16_7
int128_t v6_9 = v1_1 ^ v3_1
uint128_t v4_11 = v5_7 ^ v4_3
int128_t v0_1 = v5_7 ^ v0
v5_7.d = v6_9.d u>> 0x18
v5_7:4.d = v6_9:4.d u>> 0x18
v5_7:8.d = v6_9:8.d u>> 0x18
v5_7:0xc.d = v6_9:0xc.d u>> 0x18
v7_2.d = v6_9.d << 8
v7_2:4.d = v6_9:4.d << 8
v7_2:8.d = v6_9:8.d << 8
v7_2:0xc.d = v6_9:0xc.d << 8
v16_7.d = v6_9.d u>> 8
v16_7:4.d = v6_9:4.d u>> 8
v16_7:8.d = v6_9:8.d u>> 8
v16_7:0xc.d = v6_9:0xc.d u>> 8
v17.d = v6_9.d << 0x18
v17:4.d = v6_9:4.d << 0x18
v17:8.d = v6_9:8.d << 0x18
v17:0xc.d = v6_9:0xc.d << 0x18
v18.d = v4_11.d u>> 0x18
v18:4.d = v4_11:4.d u>> 0x18
v18:8.d = v4_11:8.d u>> 0x18
v18:0xc.d = v4_11:0xc.d u>> 0x18
v19.d = v4_11.d << 8
v19:4.d = v4_11:4.d << 8
v19:8.d = v4_11:8.d << 8
v19:0xc.d = v4_11:0xc.d << 8
uint128_t v5_8 = vorrq_s8(v7_2, v5_7)
v7_2.d = v4_11.d u>> 8
v7_2:4.d = v4_11:4.d u>> 8
v7_2:8.d = v4_11:8.d u>> 8
v7_2:0xc.d = v4_11:0xc.d u>> 8
uint128_t v16_8 = vorrq_s8(v17, v16_7)
v17.d = v4_11.d << 0x18
v17:4.d = v4_11:4.d << 0x18
v17:8.d = v4_11:8.d << 0x18
v17:0xc.d = v4_11:0xc.d << 0x18
int128_t v5_10 = v5_8 ^ v6_9 ^ v16_8
uint128_t v4_13 = vorrq_s8(v19, v18) ^ v4_11 ^ vorrq_s8(v17, v7_2)
uint128_t v0_2 = v0_1 ^ v5_10
uint128_t v2_2 = v4_3 ^ v2 ^ v5_10
uint128_t v3_2 = v3_1 ^ v4_13
uint128_t v1_2 = v1_1 ^ v4_13
uint128_t v4_14 = vzip1q_s32(v0_2, v2_2)
uint128_t v0_3 = vzip2q_s32(v0_2, v2_2)
uint128_t v2_3 = vzip1q_s32(v3_2, v1_2)
uint128_t v1_3 = vzip2q_s32(v3_2, v1_2)
uint128_t v3_3 = vzip1q_s32(v4_14, v2_3)
uint128_t v2_4 = vzip2q_s32(v4_14, v2_3)
uint128_t v4_15 = vzip1q_s32(v0_3, v1_3)
uint128_t v0_4 = vzip2q_s32(v0_3, v1_3)
uint128_t v1_4 = vrev32q_s8(v3_3)
uint128_t v2_5 = vrev32q_s8(v2_4)
uint128_t v3_4 = vrev32q_s8(v4_15)
uint128_t v0_5 = vrev32q_s8(v0_4)
uint128_t* entry_x2
*entry_x2 = v1_4
entry_x2[1] = v2_5
entry_x2[2] = v3_4
entry_x2[3] = v0_5
