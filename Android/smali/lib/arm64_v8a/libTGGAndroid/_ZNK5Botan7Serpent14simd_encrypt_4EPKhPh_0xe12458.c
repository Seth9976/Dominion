// 函数: _ZNK5Botan7Serpent14simd_encrypt_4EPKhPh
// 地址: 0xe12458
// 来自: E:\torrent\Cursor\Dominion_1.0.3315\split_config.arm64_v8a\lib\arm64-v8a\libTGGAndroid.so

int32_t* x8_2 = *(arg1 + 8)
uint128_t v2 = *(arg2 + 0x10)
uint128_t v0 = *(arg2 + 0x20)
uint128_t v3 = *(arg2 + 0x30)
uint128_t v1 = *arg2
uint128_t v5 = vzip1q_s32(v2, v3)
uint128_t v2_1 = vzip2q_s32(v2, v3)
int32_t temp0 = *x8_2
v3.d = temp0
v3:4.d = temp0
v3:8.d = temp0
v3:0xc.d = temp0
int32_t temp0_1 = x8_2[2]
int128_t v6
v6.d = temp0_1
v6:4.d = temp0_1
v6:8.d = temp0_1
v6:0xc.d = temp0_1
uint128_t v4 = vzip1q_s32(v1, v0)
uint128_t v1_1 = vzip2q_s32(v1, v0)
int32_t temp0_2 = x8_2[3]
v0.d = temp0_2
v0:4.d = temp0_2
v0:8.d = temp0_2
v0:0xc.d = temp0_2
uint128_t v7 = vzip1q_s32(v4, v5)
uint128_t v4_1 = vzip2q_s32(v4, v5)
uint128_t v5_2 = v6 ^ vzip1q_s32(v1_1, v2_1)
int32_t temp0_3 = *x8_2
v6.d = temp0_3
v6:4.d = temp0_3
v6:8.d = temp0_3
v6:0xc.d = temp0_3
uint128_t v3_1 = v3 ^ v7
uint128_t v0_1 = v0 ^ vzip2q_s32(v1_1, v2_1)
uint128_t v7_1 = v0_1 ^ v3_1
int128_t v4_2 = v6 ^ v4_1
uint128_t v3_2 = (v7_1 & v4_2) ^ v3_1
int128_t v4_3 = v5_2 ^ v4_2
uint128_t v6_2 = v7_1 ^ v5_2
uint128_t v0_3 = vorrq_s8(v0_1, v3_1) ^ v4_3
int128_t v4_4 = v7_1 ^ v4_3
uint128_t v4_5 = vorrq_s8(v3_2, v5_2) ^ v4_4
int128_t v5_5 = (v3_2 | not.o(v4_4)) ^ vorrq_s8(v0_3, v6_2)
int128_t v3_3 = v5_5 ^ v6_2 ^ v3_2
int128_t v6_3
v6_3.d = v4_5.d u>> 0x1d
v6_3:4.d = v4_5:4.d u>> 0x1d
v6_3:8.d = v4_5:8.d u>> 0x1d
v6_3:0xc.d = v4_5:0xc.d u>> 0x1d
v4_5.d <<= 3
v4_5:4.d <<= 3
v4_5:8.d <<= 3
v4_5:0xc.d <<= 3
uint128_t v4_6 = vorrq_s8(v4_5, v6_3)
v6_3.d = v3_3.d u>> 0x13
v6_3:4.d = v3_3:4.d u>> 0x13
v6_3:8.d = v3_3:8.d u>> 0x13
v6_3:0xc.d = v3_3:0xc.d u>> 0x13
v3_3.d <<= 0xd
v3_3:4.d <<= 0xd
v3_3:8.d <<= 0xd
v3_3:0xc.d <<= 0xd
uint128_t v3_4 = vorrq_s8(v3_3, v6_3)
int32_t temp0_4 = x8_2[5]
v2_1.d = temp0_4
v2_1:4.d = temp0_4
v2_1:8.d = temp0_4
v2_1:0xc.d = temp0_4
int128_t v5_7 = v5_5 ^ v4_6 ^ v3_4
v6_3.d = v3_4.d << 3
v6_3:4.d = v3_4:4.d << 3
v6_3:8.d = v3_4:8.d << 3
v6_3:0xc.d = v3_4:0xc.d << 3
int128_t v0_5 = v4_6 ^ v0_3 ^ v6_3
v6_3.d = v5_7.d u>> 0x1f
v6_3:4.d = v5_7:4.d u>> 0x1f
v6_3:8.d = v5_7:8.d u>> 0x1f
v6_3:0xc.d = v5_7:0xc.d u>> 0x1f
v5_7.d <<= 1
v5_7:4.d <<= 1
v5_7:8.d <<= 1
v5_7:0xc.d <<= 1
int32_t temp0_5 = x8_2[7]
v1_1.d = temp0_5
v1_1:4.d = temp0_5
v1_1:8.d = temp0_5
v1_1:0xc.d = temp0_5
int128_t v7_2
v7_2.d = x8_2[4]
uint128_t v5_8 = vorrq_s8(v5_7, v6_3)
v6_3.d = v0_5.d u>> 0x19
v6_3:4.d = v0_5:4.d u>> 0x19
v6_3:8.d = v0_5:8.d u>> 0x19
v6_3:0xc.d = v0_5:0xc.d u>> 0x19
v0_5.d <<= 7
v0_5:4.d <<= 7
v0_5:8.d <<= 7
v0_5:0xc.d <<= 7
uint128_t v0_6 = vorrq_s8(v0_5, v6_3)
v6_3.d = x8_2[6]
uint128_t v3_5 = v5_8 ^ v3_4
uint128_t v2_2 = v5_8 ^ v2_1
v5_8.d <<= 7
v5_8:4.d <<= 7
v5_8:8.d <<= 7
v5_8:0xc.d <<= 7
uint128_t v3_6 = v3_5 ^ v0_6
uint128_t v1_2 = v0_6 ^ v1_1
uint128_t v0_7 = v5_8 ^ v4_6 ^ v0_6
uint128_t v4_7
v4_7.d = v3_6.d u>> 0x1b
v4_7:4.d = v3_6:4.d u>> 0x1b
v4_7:8.d = v3_6:8.d u>> 0x1b
v4_7:0xc.d = v3_6:0xc.d u>> 0x1b
v3_6.d <<= 5
v3_6:4.d <<= 5
v3_6:8.d <<= 5
v3_6:0xc.d <<= 5
uint128_t v7_4 = vdupq_laneq_s32(not.o(v7_2), 0)
uint128_t v3_7 = vorrq_s8(v3_6, v4_7)
v4_7.d = v0_7.d u>> 0xa
v4_7:4.d = v0_7:4.d u>> 0xa
v4_7:8.d = v0_7:8.d u>> 0xa
v4_7:0xc.d = v0_7:0xc.d u>> 0xa
v0_7.d <<= 0x16
v0_7:4.d <<= 0x16
v0_7:8.d <<= 0x16
v0_7:0xc.d <<= 0x16
uint128_t v3_8 = v7_4 ^ v3_7
uint128_t v4_8 = v3_8 & v2_2
uint128_t v0_10 = vdupq_laneq_s32(not.o(v6_3), 0) ^ vorrq_s8(v0_7, v4_7) ^ v4_8
uint128_t v4_9 = vorrq_s8(v4_8, v1_2)
uint128_t v2_3 = v4_9 ^ v2_2
uint128_t v4_10 = v4_9 ^ v3_8
uint128_t v1_3 = v0_10 ^ v1_2
uint128_t v3_9 = vorrq_s8(v2_3, v3_8)
uint128_t v2_4 = v1_3 ^ v2_3
uint128_t v6_5
v6_5.d = v1_3.d u>> 0x1d
v6_5:4.d = v1_3:4.d u>> 0x1d
v6_5:8.d = v1_3:8.d u>> 0x1d
v6_5:0xc.d = v1_3:0xc.d u>> 0x1d
v1_3.d <<= 3
v1_3:4.d <<= 3
v1_3:8.d <<= 3
v1_3:0xc.d <<= 3
uint128_t v0_12 = vorrq_s8(v4_10, v0_10) & v3_9
uint128_t v1_4 = vorrq_s8(v1_3, v6_5)
v6_5.d = v0_12.d u>> 0x13
v6_5:4.d = v0_12:4.d u>> 0x13
v6_5:8.d = v0_12:8.d u>> 0x13
v6_5:0xc.d = v0_12:0xc.d u>> 0x13
v7_4.d = v0_12.d << 0xd
v7_4:4.d = v0_12:4.d << 0xd
v7_4:8.d = v0_12:8.d << 0xd
v7_4:0xc.d = v0_12:0xc.d << 0xd
uint128_t v6_6 = vorrq_s8(v7_4, v6_5)
uint128_t v4_11 = v2_4 ^ v4_10
int32_t temp0_6 = x8_2[8]
v5_8.d = temp0_6
v5_8:4.d = temp0_6
v5_8:8.d = temp0_6
v5_8:0xc.d = temp0_6
uint128_t v0_14 = v3_9 ^ v1_4 ^ v6_6 ^ (v0_12 & v4_11)
uint128_t v3_11
v3_11.d = v6_6.d << 3
v3_11:4.d = v6_6:4.d << 3
v3_11:8.d = v6_6:8.d << 3
v3_11:0xc.d = v6_6:0xc.d << 3
int32_t temp0_7 = x8_2[9]
v7_4.d = temp0_7
v7_4:4.d = temp0_7
v7_4:8.d = temp0_7
v7_4:0xc.d = temp0_7
uint128_t v2_7 = v4_11 ^ v1_4 ^ (v0_12 & v2_4) ^ v3_11
v3_11.d = v0_14.d u>> 0x1f
v3_11:4.d = v0_14:4.d u>> 0x1f
v3_11:8.d = v0_14:8.d u>> 0x1f
v3_11:0xc.d = v0_14:0xc.d u>> 0x1f
v0_14.d <<= 1
v0_14:4.d <<= 1
v0_14:8.d <<= 1
v0_14:0xc.d <<= 1
int32_t temp0_8 = x8_2[0xa]
uint128_t v4_12
v4_12.d = temp0_8
v4_12:4.d = temp0_8
v4_12:8.d = temp0_8
v4_12:0xc.d = temp0_8
uint128_t v0_15 = vorrq_s8(v0_14, v3_11)
v3_11.d = v2_7.d u>> 0x19
v3_11:4.d = v2_7:4.d u>> 0x19
v3_11:8.d = v2_7:8.d u>> 0x19
v3_11:0xc.d = v2_7:0xc.d u>> 0x19
v2_7.d <<= 7
v2_7:4.d <<= 7
v2_7:8.d <<= 7
v2_7:0xc.d <<= 7
uint128_t v2_8 = vorrq_s8(v2_7, v3_11)
int32_t temp0_9 = x8_2[0xb]
v3_11.d = temp0_9
v3_11:4.d = temp0_9
v3_11:8.d = temp0_9
v3_11:0xc.d = temp0_9
uint128_t v7_5 = v0_15 ^ v7_4
uint128_t v3_12 = v2_8 ^ v3_11
uint128_t v2_9 = v0_15 ^ v6_6 ^ v2_8
v0_15.d <<= 7
v0_15:4.d <<= 7
v0_15:8.d <<= 7
v0_15:0xc.d <<= 7
uint128_t v0_16 = v2_8 ^ v1_4 ^ v0_15
uint128_t v1_5
v1_5.d = v2_9.d u>> 0x1b
v1_5:4.d = v2_9:4.d u>> 0x1b
v1_5:8.d = v2_9:8.d u>> 0x1b
v1_5:0xc.d = v2_9:0xc.d u>> 0x1b
v2_9.d <<= 5
v2_9:4.d <<= 5
v2_9:8.d <<= 5
v2_9:0xc.d <<= 5
uint128_t v1_6 = vorrq_s8(v2_9, v1_5)
v2_9.d = v0_16.d u>> 0xa
v2_9:4.d = v0_16:4.d u>> 0xa
v2_9:8.d = v0_16:8.d u>> 0xa
v2_9:0xc.d = v0_16:0xc.d u>> 0xa
v0_16.d <<= 0x16
v0_16:4.d <<= 0x16
v0_16:8.d <<= 0x16
v0_16:0xc.d <<= 0x16
uint128_t v1_7 = v1_6 ^ v5_8
uint128_t v0_18 = vorrq_s8(v0_16, v2_9) ^ v4_12
uint128_t v4_14 = (v0_18 & v1_7) ^ v3_12
uint128_t v0_20 = v0_18 ^ v7_5 ^ v4_14
uint128_t v3_14 = vorrq_s8(v1_7, v3_12) ^ v7_5
uint128_t v1_8 = v0_20 ^ v1_7
v7_5.d = v0_20.d u>> 0x13
v7_5:4.d = v0_20:4.d u>> 0x13
v7_5:8.d = v0_20:8.d u>> 0x13
v7_5:0xc.d = v0_20:0xc.d u>> 0x13
v0_20.d <<= 0xd
v0_20:4.d <<= 0xd
v0_20:8.d <<= 0xd
v0_20:0xc.d <<= 0xd
uint128_t v0_21 = vorrq_s8(v0_20, v7_5)
uint128_t v7_7 = v1_8 ^ (v4_14 & v3_14)
uint128_t v1_10 = vorrq_s8(v1_8, v3_14) ^ v4_14
v4_14.d = v0_21.d << 3
v4_14:4.d = v0_21:4.d << 3
v4_14:8.d = v0_21:8.d << 3
v4_14:0xc.d = v0_21:0xc.d << 3
uint128_t v3_16 = v7_7 ^ v3_14 ^ v1_10
uint128_t v4_15 = v4_14 ^ v7_7
v7_7.d = v3_16.d u>> 0x1d
v7_7:4.d = v3_16:4.d u>> 0x1d
v7_7:8.d = v3_16:8.d u>> 0x1d
v7_7:0xc.d = v3_16:0xc.d u>> 0x1d
v3_16.d <<= 3
v3_16:4.d <<= 3
v3_16:8.d <<= 3
v3_16:0xc.d <<= 3
int32_t temp0_10 = x8_2[0xc]
uint128_t v6_7
v6_7.d = temp0_10
v6_7:4.d = temp0_10
v6_7:8.d = temp0_10
v6_7:0xc.d = temp0_10
uint128_t v3_17 = vorrq_s8(v3_16, v7_7)
int32_t temp0_11 = x8_2[0xd]
v2_9.d = temp0_11
v2_9:4.d = temp0_11
v2_9:8.d = temp0_11
v2_9:0xc.d = temp0_11
uint128_t v1_12 = v1_10 ^ v0_21 ^ v3_17
uint128_t v4_17 = not.o(v4_15 ^ v3_17)
v7_7.d = v1_12.d u>> 0x1f
v7_7:4.d = v1_12:4.d u>> 0x1f
v7_7:8.d = v1_12:8.d u>> 0x1f
v7_7:0xc.d = v1_12:0xc.d u>> 0x1f
v1_12.d <<= 1
v1_12:4.d <<= 1
v1_12:8.d <<= 1
v1_12:0xc.d <<= 1
uint128_t v1_13 = vorrq_s8(v1_12, v7_7)
v7_7.d = v4_17.d u>> 0x19
v7_7:4.d = v4_17:4.d u>> 0x19
v7_7:8.d = v4_17:8.d u>> 0x19
v7_7:0xc.d = v4_17:0xc.d u>> 0x19
v4_17.d <<= 7
v4_17:4.d <<= 7
v4_17:8.d <<= 7
v4_17:0xc.d <<= 7
int32_t temp0_12 = x8_2[0xe]
v5_8.d = temp0_12
v5_8:4.d = temp0_12
v5_8:8.d = temp0_12
v5_8:0xc.d = temp0_12
uint128_t v4_18 = vorrq_s8(v4_17, v7_7)
int32_t temp0_13 = x8_2[0xf]
v7_7.d = temp0_13
v7_7:4.d = temp0_13
v7_7:8.d = temp0_13
v7_7:0xc.d = temp0_13
uint128_t v0_23 = v1_13 ^ v0_21 ^ v4_18
uint128_t v2_10 = v1_13 ^ v2_9
v1_13.d <<= 7
v1_13:4.d <<= 7
v1_13:8.d <<= 7
v1_13:0xc.d <<= 7
uint128_t v1_14 = v4_18 ^ v3_17 ^ v1_13
uint128_t v3_18
v3_18.d = v0_23.d u>> 0x1b
v3_18:4.d = v0_23:4.d u>> 0x1b
v3_18:8.d = v0_23:8.d u>> 0x1b
v3_18:0xc.d = v0_23:0xc.d u>> 0x1b
v0_23.d <<= 5
v0_23:4.d <<= 5
v0_23:8.d <<= 5
v0_23:0xc.d <<= 5
uint128_t v0_24 = vorrq_s8(v0_23, v3_18)
v3_18.d = v1_14.d u>> 0xa
v3_18:4.d = v1_14:4.d u>> 0xa
v3_18:8.d = v1_14:8.d u>> 0xa
v3_18:0xc.d = v1_14:0xc.d u>> 0xa
v1_14.d <<= 0x16
v1_14:4.d <<= 0x16
v1_14:8.d <<= 0x16
v1_14:0xc.d <<= 0x16
uint128_t v4_19 = v4_18 ^ v7_7
uint128_t v0_25 = v0_24 ^ v6_7
uint128_t v1_16 = vorrq_s8(v1_14, v3_18) ^ v5_8
uint128_t v3_19 = v4_19 ^ v2_10
uint128_t v4_20 = vorrq_s8(v0_25, v4_19)
uint128_t v2_11 = v0_25 & v2_10
uint128_t v0_26 = v1_16 ^ v0_25
uint128_t v1_17 = v1_16 ^ v3_19
uint128_t v3_21 = vorrq_s8(v2_11, v0_26) ^ (v4_20 & v3_19)
uint128_t v4_21 = v2_11 ^ v4_20
uint128_t v0_28 = (v4_21 & v0_26) ^ v1_17
uint128_t v1_18 = vorrq_s8(v3_21 ^ v2_11, v4_21) ^ v1_17
uint128_t v5_9
v5_9.d = v3_21.d u>> 0x1d
v5_9:4.d = v3_21:4.d u>> 0x1d
v5_9:8.d = v3_21:8.d u>> 0x1d
v5_9:0xc.d = v3_21:0xc.d u>> 0x1d
v6_7.d = v3_21.d << 3
v6_7:4.d = v3_21:4.d << 3
v6_7:8.d = v3_21:8.d << 3
v6_7:0xc.d = v3_21:0xc.d << 3
uint128_t v3_23 = (v1_18 & not.o(v3_21)) ^ v4_21
uint128_t v5_10 = vorrq_s8(v6_7, v5_9)
v4_21.d = v3_23.d u>> 0x13
v4_21:4.d = v3_23:4.d u>> 0x13
v4_21:8.d = v3_23:8.d u>> 0x13
v4_21:0xc.d = v3_23:0xc.d u>> 0x13
v3_23.d <<= 0xd
v3_23:4.d <<= 0xd
v3_23:8.d <<= 0xd
v3_23:0xc.d <<= 0xd
uint128_t v3_24 = vorrq_s8(v3_23, v4_21)
int32_t temp0_14 = x8_2[0x10]
v7_7.d = temp0_14
v7_7:4.d = temp0_14
v7_7:8.d = temp0_14
v7_7:0xc.d = temp0_14
uint128_t v1_20 = v1_18 ^ v5_10 ^ v3_24
v4_21.d = v3_24.d << 3
v4_21:4.d = v3_24:4.d << 3
v4_21:8.d = v3_24:8.d << 3
v4_21:0xc.d = v3_24:0xc.d << 3
int32_t temp0_15 = x8_2[0x11]
v6_7.d = temp0_15
v6_7:4.d = temp0_15
v6_7:8.d = temp0_15
v6_7:0xc.d = temp0_15
uint128_t v0_30 = v0_28 ^ v5_10 ^ v4_21
v4_21.d = v1_20.d u>> 0x1f
v4_21:4.d = v1_20:4.d u>> 0x1f
v4_21:8.d = v1_20:8.d u>> 0x1f
v4_21:0xc.d = v1_20:0xc.d u>> 0x1f
v1_20.d <<= 1
v1_20:4.d <<= 1
v1_20:8.d <<= 1
v1_20:0xc.d <<= 1
int32_t temp0_16 = x8_2[0x12]
uint128_t v2_13
v2_13.d = temp0_16
v2_13:4.d = temp0_16
v2_13:8.d = temp0_16
v2_13:0xc.d = temp0_16
uint128_t v1_21 = vorrq_s8(v1_20, v4_21)
v4_21.d = v0_30.d u>> 0x19
v4_21:4.d = v0_30:4.d u>> 0x19
v4_21:8.d = v0_30:8.d u>> 0x19
v4_21:0xc.d = v0_30:0xc.d u>> 0x19
v0_30.d <<= 7
v0_30:4.d <<= 7
v0_30:8.d <<= 7
v0_30:0xc.d <<= 7
uint128_t v0_31 = vorrq_s8(v0_30, v4_21)
int32_t temp0_17 = x8_2[0x13]
v4_21.d = temp0_17
v4_21:4.d = temp0_17
v4_21:8.d = temp0_17
v4_21:0xc.d = temp0_17
uint128_t v3_26 = v1_21 ^ v3_24 ^ v0_31
uint128_t v6_8 = v1_21 ^ v6_7
v1_21.d <<= 7
v1_21:4.d <<= 7
v1_21:8.d <<= 7
v1_21:0xc.d <<= 7
uint128_t v0_32 = v0_31 ^ v4_21
uint128_t v1_22 = v0_31 ^ v5_10 ^ v1_21
uint128_t v5_11
v5_11.d = v3_26.d u>> 0x1b
v5_11:4.d = v3_26:4.d u>> 0x1b
v5_11:8.d = v3_26:8.d u>> 0x1b
v5_11:0xc.d = v3_26:0xc.d u>> 0x1b
v3_26.d <<= 5
v3_26:4.d <<= 5
v3_26:8.d <<= 5
v3_26:0xc.d <<= 5
uint128_t v5_12 = not.o(v0_32)
uint128_t v5_13 = v7_7 ^ v5_12
v7_7.d = v1_22.d u>> 0xa
v7_7:4.d = v1_22:4.d u>> 0xa
v7_7:8.d = v1_22:8.d u>> 0xa
v7_7:0xc.d = v1_22:0xc.d u>> 0xa
v1_22.d <<= 0x16
v1_22:4.d <<= 0x16
v1_22:8.d <<= 0x16
v1_22:0xc.d <<= 0x16
uint128_t v0_33 = v0_32 ^ v6_8
uint128_t v3_28 = v5_13 ^ vorrq_s8(v3_26, v5_11)
uint128_t v1_24 = v2_13 ^ v5_12 ^ vorrq_s8(v1_22, v7_7)
uint128_t v0_34 = v3_28 ^ v0_33
uint128_t v2_16 = v1_24 ^ (v3_28 & v0_33)
uint128_t v1_25 = v1_24 & v0_34
uint128_t v5_14 = v1_25 ^ not.o(v6_8)
uint128_t v7_9 = v2_16 & not.o(v6_8)
uint128_t v0_35 = vorrq_s8(v2_16, v0_34)
uint128_t v1_26 = v1_25 ^ v6_8
v6_8.d = v2_16.d u>> 0x13
v6_8:4.d = v2_16:4.d u>> 0x13
v6_8:8.d = v2_16:8.d u>> 0x13
v6_8:0xc.d = v2_16:0xc.d u>> 0x13
v2_16.d <<= 0xd
v2_16:4.d <<= 0xd
v2_16:8.d <<= 0xd
v2_16:0xc.d <<= 0xd
uint128_t v2_17 = vorrq_s8(v2_16, v6_8)
uint128_t v6_9 = v7_9 ^ v3_28
uint128_t v1_27 = v1_26 ^ vorrq_s8(v7_9, v3_28)
uint128_t v0_38 = v7_9 ^ v0_35 ^ v2_17 ^ (v6_9 & v5_14)
uint128_t v5_15
v5_15.d = v2_17.d << 3
v5_15:4.d = v2_17:4.d << 3
v5_15:8.d = v2_17:8.d << 3
v5_15:0xc.d = v2_17:0xc.d << 3
uint128_t v5_16 = v6_9 ^ v5_15
v6_9.d = v1_27.d u>> 0x1d
v6_9:4.d = v1_27:4.d u>> 0x1d
v6_9:8.d = v1_27:8.d u>> 0x1d
v6_9:0xc.d = v1_27:0xc.d u>> 0x1d
v1_27.d <<= 3
v1_27:4.d <<= 3
v1_27:8.d <<= 3
v1_27:0xc.d <<= 3
uint128_t v1_28 = vorrq_s8(v1_27, v6_9)
int32_t temp0_18 = x8_2[0x14]
v4_21.d = temp0_18
v4_21:4.d = temp0_18
v4_21:8.d = temp0_18
v4_21:0xc.d = temp0_18
uint128_t v0_39 = v0_38 ^ v1_28
int32_t temp0_19 = x8_2[0x15]
v7_9.d = temp0_19
v7_9:4.d = temp0_19
v7_9:8.d = temp0_19
v7_9:0xc.d = temp0_19
uint128_t v5_17 = v5_16 ^ v1_28
v6_9.d = v0_39.d u>> 0x1f
v6_9:4.d = v0_39:4.d u>> 0x1f
v6_9:8.d = v0_39:8.d u>> 0x1f
v6_9:0xc.d = v0_39:0xc.d u>> 0x1f
v0_39.d <<= 1
v0_39:4.d <<= 1
v0_39:8.d <<= 1
v0_39:0xc.d <<= 1
int32_t temp0_20 = x8_2[0x16]
uint128_t v3_29
v3_29.d = temp0_20
v3_29:4.d = temp0_20
v3_29:8.d = temp0_20
v3_29:0xc.d = temp0_20
uint128_t v0_40 = vorrq_s8(v0_39, v6_9)
v6_9.d = v5_17.d u>> 0x19
v6_9:4.d = v5_17:4.d u>> 0x19
v6_9:8.d = v5_17:8.d u>> 0x19
v6_9:0xc.d = v5_17:0xc.d u>> 0x19
v5_17.d <<= 7
v5_17:4.d <<= 7
v5_17:8.d <<= 7
v5_17:0xc.d <<= 7
uint128_t v5_18 = vorrq_s8(v5_17, v6_9)
int32_t temp0_21 = x8_2[0x17]
v6_9.d = temp0_21
v6_9:4.d = temp0_21
v6_9:8.d = temp0_21
v6_9:0xc.d = temp0_21
uint128_t v2_18 = v0_40 ^ v2_17
uint128_t v7_10 = v0_40 ^ v7_9
uint128_t v6_10 = v5_18 ^ v6_9
v0_40.d <<= 7
v0_40:4.d <<= 7
v0_40:8.d <<= 7
v0_40:0xc.d <<= 7
uint128_t v2_19 = v2_18 ^ v5_18
uint128_t v0_41 = v5_18 ^ v1_28 ^ v0_40
uint128_t v1_31 = v3_29 ^ not.o(v6_10)
v3_29.d = v2_19.d u>> 0x1b
v3_29:4.d = v2_19:4.d u>> 0x1b
v3_29:8.d = v2_19:8.d u>> 0x1b
v3_29:0xc.d = v2_19:0xc.d u>> 0x1b
v2_19.d <<= 5
v2_19:4.d <<= 5
v2_19:8.d <<= 5
v2_19:0xc.d <<= 5
uint128_t v2_20 = vorrq_s8(v2_19, v3_29)
v3_29.d = v0_41.d u>> 0xa
v3_29:4.d = v0_41:4.d u>> 0xa
v3_29:8.d = v0_41:8.d u>> 0xa
v3_29:0xc.d = v0_41:0xc.d u>> 0xa
v0_41.d <<= 0x16
v0_41:4.d <<= 0x16
v0_41:8.d <<= 0x16
v0_41:0xc.d <<= 0x16
uint128_t v2_21 = v7_10 ^ v4_21 ^ v2_20
uint128_t v4_23 = v6_10 ^ v7_10
uint128_t v0_43 = v1_31 ^ vorrq_s8(v0_41, v3_29)
uint128_t v4_24 = vorrq_s8(v0_43, v4_23)
uint128_t v0_44 = (v2_21 & v4_23) ^ v0_43
int128_t v6_11 = v0_44 & not.o(v6_10)
uint128_t v1_34 = v4_24 ^ v7_10 ^ v0_44
v7_10.d = v0_44.d u>> 0x13
v7_10:4.d = v0_44:4.d u>> 0x13
v7_10:8.d = v0_44:8.d u>> 0x13
v7_10:0xc.d = v0_44:0xc.d u>> 0x13
v0_44.d <<= 0xd
v0_44:4.d <<= 0xd
v0_44:8.d <<= 0xd
v0_44:0xc.d <<= 0xd
int128_t v6_12 = v6_11 ^ v2_21
uint128_t v0_45 = vorrq_s8(v0_44, v7_10)
uint128_t v2_23 = (v6_12 & v2_21) ^ not.o(v1_34)
uint128_t v7_11
v7_11.d = v0_45.d << 3
v7_11:4.d = v0_45:4.d << 3
v7_11:8.d = v0_45:8.d << 3
v7_11:0xc.d = v0_45:0xc.d << 3
uint128_t v4_26
v4_26.d = v2_23.d u>> 0x1d
v4_26:4.d = v2_23:4.d u>> 0x1d
v4_26:8.d = v2_23:8.d u>> 0x1d
v4_26:0xc.d = v2_23:0xc.d u>> 0x1d
v2_23.d <<= 3
v2_23:4.d <<= 3
v2_23:8.d <<= 3
v2_23:0xc.d <<= 3
int32_t temp0_22 = x8_2[0x18]
v5_18.d = temp0_22
v5_18:4.d = temp0_22
v5_18:8.d = temp0_22
v5_18:0xc.d = temp0_22
uint128_t v2_24 = vorrq_s8(v2_23, v4_26)
int32_t temp0_23 = x8_2[0x19]
v3_29.d = temp0_23
v3_29:4.d = temp0_23
v3_29:8.d = temp0_23
v3_29:0xc.d = temp0_23
int128_t v4_27 = v6_12 ^ v0_45 ^ v2_24
uint128_t v1_38 = not.o(v4_24 ^ v2_21 ^ v7_11 ^ (v6_12 | not.o(v1_34)) ^ v2_24)
int128_t v6_13
v6_13.d = v4_27.d u>> 0x1f
v6_13:4.d = v4_27:4.d u>> 0x1f
v6_13:8.d = v4_27:8.d u>> 0x1f
v6_13:0xc.d = v4_27:0xc.d u>> 0x1f
v4_27.d <<= 1
v4_27:4.d <<= 1
v4_27:8.d <<= 1
v4_27:0xc.d <<= 1
uint128_t v4_28 = vorrq_s8(v4_27, v6_13)
v6_13.d = v1_38.d u>> 0x19
v6_13:4.d = v1_38:4.d u>> 0x19
v6_13:8.d = v1_38:8.d u>> 0x19
v6_13:0xc.d = v1_38:0xc.d u>> 0x19
v1_38.d <<= 7
v1_38:4.d <<= 7
v1_38:8.d <<= 7
v1_38:0xc.d <<= 7
int32_t temp0_24 = x8_2[0x1a]
v7_11.d = temp0_24
v7_11:4.d = temp0_24
v7_11:8.d = temp0_24
v7_11:0xc.d = temp0_24
uint128_t v1_39 = vorrq_s8(v1_38, v6_13)
int32_t temp0_25 = x8_2[0x1b]
v6_13.d = temp0_25
v6_13:4.d = temp0_25
v6_13:8.d = temp0_25
v6_13:0xc.d = temp0_25
uint128_t v0_47 = v4_28 ^ v0_45 ^ v1_39
uint128_t v3_30 = v4_28 ^ v3_29
v4_28.d <<= 7
v4_28:4.d <<= 7
v4_28:8.d <<= 7
v4_28:0xc.d <<= 7
uint128_t v2_26 = v1_39 ^ v2_24 ^ v4_28
v4_28.d = v0_47.d u>> 0x1b
v4_28:4.d = v0_47:4.d u>> 0x1b
v4_28:8.d = v0_47:8.d u>> 0x1b
v4_28:0xc.d = v0_47:0xc.d u>> 0x1b
v0_47.d <<= 5
v0_47:4.d <<= 5
v0_47:8.d <<= 5
v0_47:0xc.d <<= 5
uint128_t v0_48 = vorrq_s8(v0_47, v4_28)
v4_28.d = v2_26.d u>> 0xa
v4_28:4.d = v2_26:4.d u>> 0xa
v4_28:8.d = v2_26:8.d u>> 0xa
v4_28:0xc.d = v2_26:0xc.d u>> 0xa
v2_26.d <<= 0x16
v2_26:4.d <<= 0x16
v2_26:8.d <<= 0x16
v2_26:0xc.d <<= 0x16
int128_t v6_14 = v1_39 ^ v6_13
uint128_t v0_49 = v0_48 ^ v5_18
uint128_t v2_28 = vorrq_s8(v2_26, v4_28) ^ v7_11
int128_t v5_19 = v0_49 & v6_14
int128_t v7_13 = v5_19 ^ not.o(v2_28)
int128_t v0_50 = v0_49 ^ v6_14
uint128_t v3_31 = v3_30 ^ v7_13
uint128_t v0_51 = vorrq_s8(v3_31, v0_50)
int128_t v2_31 = (v6_14 | not.o(v2_28)) ^ v0_50 ^ v3_31
int128_t v6_16 = vorrq_s8(v0_51, v7_13) ^ v2_31
int128_t v0_53 = v7_13 ^ v6_14 ^ v0_51 ^ v6_16
uint128_t v7_14
v7_14.d = v6_16.d u>> 0x13
v7_14:4.d = v6_16:4.d u>> 0x13
v7_14:8.d = v6_16:8.d u>> 0x13
v7_14:0xc.d = v6_16:0xc.d u>> 0x13
v6_16.d <<= 0xd
v6_16:4.d <<= 0xd
v6_16:8.d <<= 0xd
v6_16:0xc.d <<= 0xd
int128_t v2_32 = v0_53 & v2_31
uint128_t v6_17 = vorrq_s8(v6_16, v7_14)
v7_14.d = v0_53.d u>> 0x1d
v7_14:4.d = v0_53:4.d u>> 0x1d
v7_14:8.d = v0_53:8.d u>> 0x1d
v7_14:0xc.d = v0_53:0xc.d u>> 0x1d
v0_53.d <<= 3
v0_53:4.d <<= 3
v0_53:8.d <<= 3
v0_53:0xc.d <<= 3
uint128_t v0_54 = vorrq_s8(v0_53, v7_14)
v7_14.d = v6_17.d << 3
v7_14:4.d = v6_17:4.d << 3
v7_14:8.d = v6_17:8.d << 3
v7_14:0xc.d = v6_17:0xc.d << 3
int32_t temp0_26 = x8_2[0x1c]
v1_39.d = temp0_26
v1_39:4.d = temp0_26
v1_39:8.d = temp0_26
v1_39:0xc.d = temp0_26
uint128_t v3_33 = v6_17 ^ v3_31 ^ v0_54
int32_t temp0_27 = x8_2[0x1d]
v4_28.d = temp0_27
v4_28:4.d = temp0_27
v4_28:8.d = temp0_27
v4_28:0xc.d = temp0_27
int128_t v2_33 = v5_19 ^ v2_28 ^ v7_14 ^ v0_54 ^ v2_32
int128_t v5_22
v5_22.d = v3_33.d u>> 0x1f
v5_22:4.d = v3_33:4.d u>> 0x1f
v5_22:8.d = v3_33:8.d u>> 0x1f
v5_22:0xc.d = v3_33:0xc.d u>> 0x1f
v3_33.d <<= 1
v3_33:4.d <<= 1
v3_33:8.d <<= 1
v3_33:0xc.d <<= 1
int32_t temp0_28 = x8_2[0x1e]
v7_14.d = temp0_28
v7_14:4.d = temp0_28
v7_14:8.d = temp0_28
v7_14:0xc.d = temp0_28
uint128_t v3_34 = vorrq_s8(v3_33, v5_22)
v5_22.d = v2_33.d u>> 0x19
v5_22:4.d = v2_33:4.d u>> 0x19
v5_22:8.d = v2_33:8.d u>> 0x19
v5_22:0xc.d = v2_33:0xc.d u>> 0x19
v2_33.d <<= 7
v2_33:4.d <<= 7
v2_33:8.d <<= 7
v2_33:0xc.d <<= 7
uint128_t v2_34 = vorrq_s8(v2_33, v5_22)
int32_t temp0_29 = x8_2[0x1f]
v5_22.d = temp0_29
v5_22:4.d = temp0_29
v5_22:8.d = temp0_29
v5_22:0xc.d = temp0_29
uint128_t v6_19 = v3_34 ^ v6_17 ^ v2_34
uint128_t v4_29 = v3_34 ^ v4_28
v3_34.d <<= 7
v3_34:4.d <<= 7
v3_34:8.d <<= 7
v3_34:0xc.d <<= 7
int128_t v2_35 = v2_34 ^ v5_22
uint128_t v3_35 = v2_34 ^ v0_54 ^ v3_34
v5_22.d = v6_19.d u>> 0x1b
v5_22:4.d = v6_19:4.d u>> 0x1b
v5_22:8.d = v6_19:8.d u>> 0x1b
v5_22:0xc.d = v6_19:0xc.d u>> 0x1b
v6_19.d <<= 5
v6_19:4.d <<= 5
v6_19:8.d <<= 5
v6_19:0xc.d <<= 5
uint128_t v5_23 = vorrq_s8(v6_19, v5_22)
v6_19.d = v3_35.d u>> 0xa
v6_19:4.d = v3_35:4.d u>> 0xa
v6_19:8.d = v3_35:8.d u>> 0xa
v6_19:0xc.d = v3_35:0xc.d u>> 0xa
v3_35.d <<= 0x16
v3_35:4.d <<= 0x16
v3_35:8.d <<= 0x16
v3_35:0xc.d <<= 0x16
uint128_t v5_24 = v5_23 ^ v1_39
uint128_t v1_40 = vorrq_s8(v3_35, v6_19) ^ v7_14
uint128_t v3_38 = vorrq_s8(v1_40, v4_29) ^ v2_35
uint128_t v7_16 = v3_38 ^ v1_40
uint128_t v1_41 = vorrq_s8(v1_40 ^ v4_29, v2_35) & v5_24
uint128_t v2_37 = v3_38 ^ v4_29
uint128_t v4_31 = v2_37 ^ v5_24 ^ vorrq_s8(v3_38, v4_29)
uint128_t v5_26 = vorrq_s8(v2_37, v5_24) ^ v7_16
uint128_t v4_33 = (v4_31 & v5_26) ^ v2_37
uint128_t v2_38 = (v5_26 | not.o(v7_16 ^ v4_31)) ^ v2_37
uint128_t v7_18
v7_18.d = v4_33.d u>> 0x1d
v7_18:4.d = v4_33:4.d u>> 0x1d
v7_18:8.d = v4_33:8.d u>> 0x1d
v7_18:0xc.d = v4_33:0xc.d u>> 0x1d
v4_33.d <<= 3
v4_33:4.d <<= 3
v4_33:8.d <<= 3
v4_33:0xc.d <<= 3
uint128_t v4_34 = vorrq_s8(v4_33, v7_18)
v7_18.d = v2_38.d u>> 0x13
v7_18:4.d = v2_38:4.d u>> 0x13
v7_18:8.d = v2_38:8.d u>> 0x13
v7_18:0xc.d = v2_38:0xc.d u>> 0x13
v2_38.d <<= 0xd
v2_38:4.d <<= 0xd
v2_38:8.d <<= 0xd
v2_38:0xc.d <<= 0xd
uint128_t v2_39 = vorrq_s8(v2_38, v7_18)
int32_t temp0_30 = x8_2[0x20]
v0_54.d = temp0_30
v0_54:4.d = temp0_30
v0_54:8.d = temp0_30
v0_54:0xc.d = temp0_30
uint128_t v3_41 = v1_41 ^ v3_38 ^ v4_34 ^ v2_39
v7_18.d = v2_39.d << 3
v7_18:4.d = v2_39:4.d << 3
v7_18:8.d = v2_39:8.d << 3
v7_18:0xc.d = v2_39:0xc.d << 3
int32_t temp0_31 = x8_2[0x21]
v6_19.d = temp0_31
v6_19:4.d = temp0_31
v6_19:8.d = temp0_31
v6_19:0xc.d = temp0_31
uint128_t v5_28 = v4_34 ^ v5_26 ^ v7_18
v7_18.d = v3_41.d u>> 0x1f
v7_18:4.d = v3_41:4.d u>> 0x1f
v7_18:8.d = v3_41:8.d u>> 0x1f
v7_18:0xc.d = v3_41:0xc.d u>> 0x1f
v3_41.d <<= 1
v3_41:4.d <<= 1
v3_41:8.d <<= 1
v3_41:0xc.d <<= 1
int32_t temp0_32 = x8_2[0x22]
uint128_t v1_42
v1_42.d = temp0_32
v1_42:4.d = temp0_32
v1_42:8.d = temp0_32
v1_42:0xc.d = temp0_32
uint128_t v3_42 = vorrq_s8(v3_41, v7_18)
v7_18.d = v5_28.d u>> 0x19
v7_18:4.d = v5_28:4.d u>> 0x19
v7_18:8.d = v5_28:8.d u>> 0x19
v7_18:0xc.d = v5_28:0xc.d u>> 0x19
v5_28.d <<= 7
v5_28:4.d <<= 7
v5_28:8.d <<= 7
v5_28:0xc.d <<= 7
uint128_t v5_29 = vorrq_s8(v5_28, v7_18)
int32_t temp0_33 = x8_2[0x23]
v7_18.d = temp0_33
v7_18:4.d = temp0_33
v7_18:8.d = temp0_33
v7_18:0xc.d = temp0_33
uint128_t v16_2 = v3_42 ^ v2_39
v2_39.d = v3_42.d << 7
v2_39:4.d = v3_42:4.d << 7
v2_39:8.d = v3_42:8.d << 7
v2_39:0xc.d = v3_42:0xc.d << 7
uint128_t v6_20 = v3_42 ^ v6_19
uint128_t v4_35 = v16_2 ^ v5_29
uint128_t v7_19 = v5_29 ^ v7_18
uint128_t v3_44 = v2_39 ^ v4_34 ^ v5_29
v5_29.d = v4_35.d u>> 0x1b
v5_29:4.d = v4_35:4.d u>> 0x1b
v5_29:8.d = v4_35:8.d u>> 0x1b
v5_29:0xc.d = v4_35:0xc.d u>> 0x1b
v4_35.d <<= 5
v4_35:4.d <<= 5
v4_35:8.d <<= 5
v4_35:0xc.d <<= 5
uint128_t v4_36 = vorrq_s8(v4_35, v5_29)
v5_29.d = v3_44.d u>> 0xa
v5_29:4.d = v3_44:4.d u>> 0xa
v5_29:8.d = v3_44:8.d u>> 0xa
v5_29:0xc.d = v3_44:0xc.d u>> 0xa
v3_44.d <<= 0x16
v3_44:4.d <<= 0x16
v3_44:8.d <<= 0x16
v3_44:0xc.d <<= 0x16
uint128_t v0_55 = v4_36 ^ v0_54
uint128_t v4_37 = v0_55 ^ v7_19
uint128_t v1_43 = vorrq_s8(v3_44, v5_29) ^ v1_42
uint128_t v6_21 = v1_43 ^ v6_20
uint128_t v0_56 = (v4_37 & v6_20) ^ v0_55
uint128_t v7_21 = v4_37 ^ v1_43
uint128_t v5_32 = vorrq_s8(v0_55, v7_19) ^ v6_21
uint128_t v4_38 = v4_37 ^ v6_21
uint128_t v1_45 = vorrq_s8(v0_56, v1_43) ^ v4_38
int128_t v4_40 = (v0_56 | not.o(v4_38)) ^ vorrq_s8(v5_32, v7_21)
uint128_t v0_57 = v4_40 ^ v7_21 ^ v0_56
uint128_t v7_22
v7_22.d = v1_45.d u>> 0x1d
v7_22:4.d = v1_45:4.d u>> 0x1d
v7_22:8.d = v1_45:8.d u>> 0x1d
v7_22:0xc.d = v1_45:0xc.d u>> 0x1d
v1_45.d <<= 3
v1_45:4.d <<= 3
v1_45:8.d <<= 3
v1_45:0xc.d <<= 3
uint128_t v1_46 = vorrq_s8(v1_45, v7_22)
v7_22.d = v0_57.d u>> 0x13
v7_22:4.d = v0_57:4.d u>> 0x13
v7_22:8.d = v0_57:8.d u>> 0x13
v7_22:0xc.d = v0_57:0xc.d u>> 0x13
v0_57.d <<= 0xd
v0_57:4.d <<= 0xd
v0_57:8.d <<= 0xd
v0_57:0xc.d <<= 0xd
uint128_t v0_58 = vorrq_s8(v0_57, v7_22)
int32_t temp0_34 = x8_2[0x25]
v2_39.d = temp0_34
v2_39:4.d = temp0_34
v2_39:8.d = temp0_34
v2_39:0xc.d = temp0_34
int128_t v4_42 = v4_40 ^ v1_46 ^ v0_58
v7_22.d = v0_58.d << 3
v7_22:4.d = v0_58:4.d << 3
v7_22:8.d = v0_58:8.d << 3
v7_22:0xc.d = v0_58:0xc.d << 3
uint128_t v5_34 = v1_46 ^ v5_32 ^ v7_22
v7_22.d = v4_42.d u>> 0x1f
v7_22:4.d = v4_42:4.d u>> 0x1f
v7_22:8.d = v4_42:8.d u>> 0x1f
v7_22:0xc.d = v4_42:0xc.d u>> 0x1f
v4_42.d <<= 1
v4_42:4.d <<= 1
v4_42:8.d <<= 1
v4_42:0xc.d <<= 1
int32_t temp0_35 = x8_2[0x27]
v3_44.d = temp0_35
v3_44:4.d = temp0_35
v3_44:8.d = temp0_35
v3_44:0xc.d = temp0_35
int128_t v6_22
v6_22.d = x8_2[0x24]
uint128_t v4_43 = vorrq_s8(v4_42, v7_22)
v7_22.d = v5_34.d u>> 0x19
v7_22:4.d = v5_34:4.d u>> 0x19
v7_22:8.d = v5_34:8.d u>> 0x19
v7_22:0xc.d = v5_34:0xc.d u>> 0x19
v5_34.d <<= 7
v5_34:4.d <<= 7
v5_34:8.d <<= 7
v5_34:0xc.d <<= 7
uint128_t v5_35 = vorrq_s8(v5_34, v7_22)
v7_22.d = x8_2[0x26]
uint128_t v0_59 = v4_43 ^ v0_58
uint128_t v2_40 = v4_43 ^ v2_39
v4_43.d <<= 7
v4_43:4.d <<= 7
v4_43:8.d <<= 7
v4_43:0xc.d <<= 7
uint128_t v0_60 = v0_59 ^ v5_35
uint128_t v3_45 = v5_35 ^ v3_44
uint128_t v1_48 = v4_43 ^ v1_46 ^ v5_35
v5_35.d = v0_60.d u>> 0x1b
v5_35:4.d = v0_60:4.d u>> 0x1b
v5_35:8.d = v0_60:8.d u>> 0x1b
v5_35:0xc.d = v0_60:0xc.d u>> 0x1b
v0_60.d <<= 5
v0_60:4.d <<= 5
v0_60:8.d <<= 5
v0_60:0xc.d <<= 5
uint128_t v6_24 = vdupq_laneq_s32(not.o(v6_22), 0)
uint128_t v0_61 = vorrq_s8(v0_60, v5_35)
v5_35.d = v1_48.d u>> 0xa
v5_35:4.d = v1_48:4.d u>> 0xa
v5_35:8.d = v1_48:8.d u>> 0xa
v5_35:0xc.d = v1_48:0xc.d u>> 0xa
v1_48.d <<= 0x16
v1_48:4.d <<= 0x16
v1_48:8.d <<= 0x16
v1_48:0xc.d <<= 0x16
uint128_t v0_62 = v6_24 ^ v0_61
uint128_t v5_36 = v0_62 & v2_40
uint128_t v1_51 = vdupq_laneq_s32(not.o(v7_22), 0) ^ vorrq_s8(v1_48, v5_35) ^ v5_36
uint128_t v5_37 = vorrq_s8(v5_36, v3_45)
uint128_t v2_41 = v5_37 ^ v2_40
uint128_t v5_38 = v5_37 ^ v0_62
uint128_t v3_46 = v1_51 ^ v3_45
uint128_t v0_63 = vorrq_s8(v2_41, v0_62)
uint128_t v2_42 = v3_46 ^ v2_41
v6_24.d = v3_46.d u>> 0x1d
v6_24:4.d = v3_46:4.d u>> 0x1d
v6_24:8.d = v3_46:8.d u>> 0x1d
v6_24:0xc.d = v3_46:0xc.d u>> 0x1d
v3_46.d <<= 3
v3_46:4.d <<= 3
v3_46:8.d <<= 3
v3_46:0xc.d <<= 3
uint128_t v1_53 = vorrq_s8(v5_38, v1_51) & v0_63
uint128_t v3_47 = vorrq_s8(v3_46, v6_24)
v6_24.d = v1_53.d u>> 0x13
v6_24:4.d = v1_53:4.d u>> 0x13
v6_24:8.d = v1_53:8.d u>> 0x13
v6_24:0xc.d = v1_53:0xc.d u>> 0x13
uint128_t v7_24
v7_24.d = v1_53.d << 0xd
v7_24:4.d = v1_53:4.d << 0xd
v7_24:8.d = v1_53:8.d << 0xd
v7_24:0xc.d = v1_53:0xc.d << 0xd
uint128_t v6_25 = vorrq_s8(v7_24, v6_24)
uint128_t v5_39 = v2_42 ^ v5_38
int32_t temp0_36 = x8_2[0x28]
v4_43.d = temp0_36
v4_43:4.d = temp0_36
v4_43:8.d = temp0_36
v4_43:0xc.d = temp0_36
uint128_t v0_66 = v0_63 ^ v3_47 ^ v6_25 ^ (v1_53 & v5_39)
uint128_t v1_54
v1_54.d = v6_25.d << 3
v1_54:4.d = v6_25:4.d << 3
v1_54:8.d = v6_25:8.d << 3
v1_54:0xc.d = v6_25:0xc.d << 3
int32_t temp0_37 = x8_2[0x29]
v7_24.d = temp0_37
v7_24:4.d = temp0_37
v7_24:8.d = temp0_37
v7_24:0xc.d = temp0_37
uint128_t v1_55 = v5_39 ^ v3_47 ^ (v1_53 & v2_42) ^ v1_54
uint128_t v2_44
v2_44.d = v0_66.d u>> 0x1f
v2_44:4.d = v0_66:4.d u>> 0x1f
v2_44:8.d = v0_66:8.d u>> 0x1f
v2_44:0xc.d = v0_66:0xc.d u>> 0x1f
v0_66.d <<= 1
v0_66:4.d <<= 1
v0_66:8.d <<= 1
v0_66:0xc.d <<= 1
int32_t temp0_38 = x8_2[0x2a]
uint128_t v5_40
v5_40.d = temp0_38
v5_40:4.d = temp0_38
v5_40:8.d = temp0_38
v5_40:0xc.d = temp0_38
uint128_t v0_67 = vorrq_s8(v0_66, v2_44)
v2_44.d = v1_55.d u>> 0x19
v2_44:4.d = v1_55:4.d u>> 0x19
v2_44:8.d = v1_55:8.d u>> 0x19
v2_44:0xc.d = v1_55:0xc.d u>> 0x19
v1_55.d <<= 7
v1_55:4.d <<= 7
v1_55:8.d <<= 7
v1_55:0xc.d <<= 7
uint128_t v1_56 = vorrq_s8(v1_55, v2_44)
int32_t temp0_39 = x8_2[0x2b]
v2_44.d = temp0_39
v2_44:4.d = temp0_39
v2_44:8.d = temp0_39
v2_44:0xc.d = temp0_39
uint128_t v7_25 = v0_67 ^ v7_24
uint128_t v2_45 = v1_56 ^ v2_44
uint128_t v1_57 = v0_67 ^ v6_25 ^ v1_56
v0_67.d <<= 7
v0_67:4.d <<= 7
v0_67:8.d <<= 7
v0_67:0xc.d <<= 7
uint128_t v0_68 = v1_56 ^ v3_47 ^ v0_67
uint128_t v3_48
v3_48.d = v1_57.d u>> 0x1b
v3_48:4.d = v1_57:4.d u>> 0x1b
v3_48:8.d = v1_57:8.d u>> 0x1b
v3_48:0xc.d = v1_57:0xc.d u>> 0x1b
v1_57.d <<= 5
v1_57:4.d <<= 5
v1_57:8.d <<= 5
v1_57:0xc.d <<= 5
uint128_t v1_58 = vorrq_s8(v1_57, v3_48)
v3_48.d = v0_68.d u>> 0xa
v3_48:4.d = v0_68:4.d u>> 0xa
v3_48:8.d = v0_68:8.d u>> 0xa
v3_48:0xc.d = v0_68:0xc.d u>> 0xa
v0_68.d <<= 0x16
v0_68:4.d <<= 0x16
v0_68:8.d <<= 0x16
v0_68:0xc.d <<= 0x16
uint128_t v1_59 = v1_58 ^ v4_43
uint128_t v0_70 = vorrq_s8(v0_68, v3_48) ^ v5_40
uint128_t v5_42 = (v0_70 & v1_59) ^ v2_45
uint128_t v0_72 = v0_70 ^ v7_25 ^ v5_42
uint128_t v2_47 = vorrq_s8(v1_59, v2_45) ^ v7_25
uint128_t v1_60 = v0_72 ^ v1_59
v7_25.d = v0_72.d u>> 0x13
v7_25:4.d = v0_72:4.d u>> 0x13
v7_25:8.d = v0_72:8.d u>> 0x13
v7_25:0xc.d = v0_72:0xc.d u>> 0x13
v0_72.d <<= 0xd
v0_72:4.d <<= 0xd
v0_72:8.d <<= 0xd
v0_72:0xc.d <<= 0xd
uint128_t v0_73 = vorrq_s8(v0_72, v7_25)
uint128_t v7_27 = v1_60 ^ (v5_42 & v2_47)
uint128_t v1_62 = vorrq_s8(v1_60, v2_47) ^ v5_42
v5_42.d = v0_73.d << 3
v5_42:4.d = v0_73:4.d << 3
v5_42:8.d = v0_73:8.d << 3
v5_42:0xc.d = v0_73:0xc.d << 3
uint128_t v2_49 = v7_27 ^ v2_47 ^ v1_62
uint128_t v5_43 = v5_42 ^ v7_27
v7_27.d = v2_49.d u>> 0x1d
v7_27:4.d = v2_49:4.d u>> 0x1d
v7_27:8.d = v2_49:8.d u>> 0x1d
v7_27:0xc.d = v2_49:0xc.d u>> 0x1d
v2_49.d <<= 3
v2_49:4.d <<= 3
v2_49:8.d <<= 3
v2_49:0xc.d <<= 3
int32_t temp0_40 = x8_2[0x2c]
uint128_t v6_26
v6_26.d = temp0_40
v6_26:4.d = temp0_40
v6_26:8.d = temp0_40
v6_26:0xc.d = temp0_40
uint128_t v2_50 = vorrq_s8(v2_49, v7_27)
int32_t temp0_41 = x8_2[0x2d]
v3_48.d = temp0_41
v3_48:4.d = temp0_41
v3_48:8.d = temp0_41
v3_48:0xc.d = temp0_41
uint128_t v1_64 = v1_62 ^ v0_73 ^ v2_50
uint128_t v5_45 = not.o(v5_43 ^ v2_50)
v7_27.d = v1_64.d u>> 0x1f
v7_27:4.d = v1_64:4.d u>> 0x1f
v7_27:8.d = v1_64:8.d u>> 0x1f
v7_27:0xc.d = v1_64:0xc.d u>> 0x1f
v1_64.d <<= 1
v1_64:4.d <<= 1
v1_64:8.d <<= 1
v1_64:0xc.d <<= 1
uint128_t v1_65 = vorrq_s8(v1_64, v7_27)
v7_27.d = v5_45.d u>> 0x19
v7_27:4.d = v5_45:4.d u>> 0x19
v7_27:8.d = v5_45:8.d u>> 0x19
v7_27:0xc.d = v5_45:0xc.d u>> 0x19
v5_45.d <<= 7
v5_45:4.d <<= 7
v5_45:8.d <<= 7
v5_45:0xc.d <<= 7
int32_t temp0_42 = x8_2[0x2e]
v4_43.d = temp0_42
v4_43:4.d = temp0_42
v4_43:8.d = temp0_42
v4_43:0xc.d = temp0_42
uint128_t v5_46 = vorrq_s8(v5_45, v7_27)
int32_t temp0_43 = x8_2[0x2f]
v7_27.d = temp0_43
v7_27:4.d = temp0_43
v7_27:8.d = temp0_43
v7_27:0xc.d = temp0_43
uint128_t v0_75 = v1_65 ^ v0_73 ^ v5_46
uint128_t v3_49 = v1_65 ^ v3_48
v1_65.d <<= 7
v1_65:4.d <<= 7
v1_65:8.d <<= 7
v1_65:0xc.d <<= 7
uint128_t v1_66 = v5_46 ^ v2_50 ^ v1_65
uint128_t v2_51
v2_51.d = v0_75.d u>> 0x1b
v2_51:4.d = v0_75:4.d u>> 0x1b
v2_51:8.d = v0_75:8.d u>> 0x1b
v2_51:0xc.d = v0_75:0xc.d u>> 0x1b
v0_75.d <<= 5
v0_75:4.d <<= 5
v0_75:8.d <<= 5
v0_75:0xc.d <<= 5
uint128_t v0_76 = vorrq_s8(v0_75, v2_51)
v2_51.d = v1_66.d u>> 0xa
v2_51:4.d = v1_66:4.d u>> 0xa
v2_51:8.d = v1_66:8.d u>> 0xa
v2_51:0xc.d = v1_66:0xc.d u>> 0xa
v1_66.d <<= 0x16
v1_66:4.d <<= 0x16
v1_66:8.d <<= 0x16
v1_66:0xc.d <<= 0x16
uint128_t v5_47 = v5_46 ^ v7_27
uint128_t v0_77 = v0_76 ^ v6_26
uint128_t v1_68 = vorrq_s8(v1_66, v2_51) ^ v4_43
uint128_t v2_52 = v5_47 ^ v3_49
uint128_t v4_44 = vorrq_s8(v0_77, v5_47)
uint128_t v3_50 = v0_77 & v3_49
uint128_t v0_78 = v1_68 ^ v0_77
uint128_t v1_69 = v1_68 ^ v2_52
uint128_t v2_54 = vorrq_s8(v3_50, v0_78) ^ (v4_44 & v2_52)
uint128_t v4_45 = v3_50 ^ v4_44
uint128_t v0_80 = (v4_45 & v0_78) ^ v1_69
uint128_t v1_70 = vorrq_s8(v2_54 ^ v3_50, v4_45) ^ v1_69
uint128_t v5_48
v5_48.d = v2_54.d u>> 0x1d
v5_48:4.d = v2_54:4.d u>> 0x1d
v5_48:8.d = v2_54:8.d u>> 0x1d
v5_48:0xc.d = v2_54:0xc.d u>> 0x1d
v6_26.d = v2_54.d << 3
v6_26:4.d = v2_54:4.d << 3
v6_26:8.d = v2_54:8.d << 3
v6_26:0xc.d = v2_54:0xc.d << 3
uint128_t v2_56 = (v1_70 & not.o(v2_54)) ^ v4_45
uint128_t v5_49 = vorrq_s8(v6_26, v5_48)
v4_45.d = v2_56.d u>> 0x13
v4_45:4.d = v2_56:4.d u>> 0x13
v4_45:8.d = v2_56:8.d u>> 0x13
v4_45:0xc.d = v2_56:0xc.d u>> 0x13
v2_56.d <<= 0xd
v2_56:4.d <<= 0xd
v2_56:8.d <<= 0xd
v2_56:0xc.d <<= 0xd
uint128_t v2_57 = vorrq_s8(v2_56, v4_45)
int32_t temp0_44 = x8_2[0x30]
v7_27.d = temp0_44
v7_27:4.d = temp0_44
v7_27:8.d = temp0_44
v7_27:0xc.d = temp0_44
uint128_t v1_72 = v1_70 ^ v5_49 ^ v2_57
v4_45.d = v2_57.d << 3
v4_45:4.d = v2_57:4.d << 3
v4_45:8.d = v2_57:8.d << 3
v4_45:0xc.d = v2_57:0xc.d << 3
int32_t temp0_45 = x8_2[0x31]
v6_26.d = temp0_45
v6_26:4.d = temp0_45
v6_26:8.d = temp0_45
v6_26:0xc.d = temp0_45
uint128_t v0_82 = v0_80 ^ v5_49 ^ v4_45
v4_45.d = v1_72.d u>> 0x1f
v4_45:4.d = v1_72:4.d u>> 0x1f
v4_45:8.d = v1_72:8.d u>> 0x1f
v4_45:0xc.d = v1_72:0xc.d u>> 0x1f
v1_72.d <<= 1
v1_72:4.d <<= 1
v1_72:8.d <<= 1
v1_72:0xc.d <<= 1
int32_t temp0_46 = x8_2[0x32]
uint128_t v3_52
v3_52.d = temp0_46
v3_52:4.d = temp0_46
v3_52:8.d = temp0_46
v3_52:0xc.d = temp0_46
uint128_t v1_73 = vorrq_s8(v1_72, v4_45)
v4_45.d = v0_82.d u>> 0x19
v4_45:4.d = v0_82:4.d u>> 0x19
v4_45:8.d = v0_82:8.d u>> 0x19
v4_45:0xc.d = v0_82:0xc.d u>> 0x19
v0_82.d <<= 7
v0_82:4.d <<= 7
v0_82:8.d <<= 7
v0_82:0xc.d <<= 7
uint128_t v0_83 = vorrq_s8(v0_82, v4_45)
int32_t temp0_47 = x8_2[0x33]
v4_45.d = temp0_47
v4_45:4.d = temp0_47
v4_45:8.d = temp0_47
v4_45:0xc.d = temp0_47
uint128_t v2_59 = v1_73 ^ v2_57 ^ v0_83
uint128_t v6_27 = v1_73 ^ v6_26
v1_73.d <<= 7
v1_73:4.d <<= 7
v1_73:8.d <<= 7
v1_73:0xc.d <<= 7
uint128_t v0_84 = v0_83 ^ v4_45
uint128_t v1_74 = v0_83 ^ v5_49 ^ v1_73
uint128_t v5_50
v5_50.d = v2_59.d u>> 0x1b
v5_50:4.d = v2_59:4.d u>> 0x1b
v5_50:8.d = v2_59:8.d u>> 0x1b
v5_50:0xc.d = v2_59:0xc.d u>> 0x1b
v2_59.d <<= 5
v2_59:4.d <<= 5
v2_59:8.d <<= 5
v2_59:0xc.d <<= 5
uint128_t v5_51 = not.o(v0_84)
uint128_t v5_52 = v7_27 ^ v5_51
v7_27.d = v1_74.d u>> 0xa
v7_27:4.d = v1_74:4.d u>> 0xa
v7_27:8.d = v1_74:8.d u>> 0xa
v7_27:0xc.d = v1_74:0xc.d u>> 0xa
v1_74.d <<= 0x16
v1_74:4.d <<= 0x16
v1_74:8.d <<= 0x16
v1_74:0xc.d <<= 0x16
uint128_t v0_85 = v0_84 ^ v6_27
uint128_t v2_61 = v5_52 ^ vorrq_s8(v2_59, v5_50)
uint128_t v1_76 = v3_52 ^ v5_51 ^ vorrq_s8(v1_74, v7_27)
uint128_t v0_86 = v2_61 ^ v0_85
uint128_t v3_55 = v1_76 ^ (v2_61 & v0_85)
uint128_t v1_77 = v1_76 & v0_86
uint128_t v5_53 = v1_77 ^ not.o(v6_27)
uint128_t v7_29 = v3_55 & not.o(v6_27)
uint128_t v0_87 = vorrq_s8(v3_55, v0_86)
uint128_t v1_78 = v1_77 ^ v6_27
v6_27.d = v3_55.d u>> 0x13
v6_27:4.d = v3_55:4.d u>> 0x13
v6_27:8.d = v3_55:8.d u>> 0x13
v6_27:0xc.d = v3_55:0xc.d u>> 0x13
v3_55.d <<= 0xd
v3_55:4.d <<= 0xd
v3_55:8.d <<= 0xd
v3_55:0xc.d <<= 0xd
uint128_t v3_56 = vorrq_s8(v3_55, v6_27)
uint128_t v6_28 = v7_29 ^ v2_61
uint128_t v1_79 = v1_78 ^ vorrq_s8(v7_29, v2_61)
uint128_t v0_90 = v7_29 ^ v0_87 ^ v3_56 ^ (v6_28 & v5_53)
uint128_t v5_54
v5_54.d = v3_56.d << 3
v5_54:4.d = v3_56:4.d << 3
v5_54:8.d = v3_56:8.d << 3
v5_54:0xc.d = v3_56:0xc.d << 3
uint128_t v5_55 = v6_28 ^ v5_54
v6_28.d = v1_79.d u>> 0x1d
v6_28:4.d = v1_79:4.d u>> 0x1d
v6_28:8.d = v1_79:8.d u>> 0x1d
v6_28:0xc.d = v1_79:0xc.d u>> 0x1d
v1_79.d <<= 3
v1_79:4.d <<= 3
v1_79:8.d <<= 3
v1_79:0xc.d <<= 3
uint128_t v1_80 = vorrq_s8(v1_79, v6_28)
int32_t temp0_48 = x8_2[0x34]
v4_45.d = temp0_48
v4_45:4.d = temp0_48
v4_45:8.d = temp0_48
v4_45:0xc.d = temp0_48
uint128_t v0_91 = v0_90 ^ v1_80
int32_t temp0_49 = x8_2[0x35]
v7_29.d = temp0_49
v7_29:4.d = temp0_49
v7_29:8.d = temp0_49
v7_29:0xc.d = temp0_49
uint128_t v5_56 = v5_55 ^ v1_80
v6_28.d = v0_91.d u>> 0x1f
v6_28:4.d = v0_91:4.d u>> 0x1f
v6_28:8.d = v0_91:8.d u>> 0x1f
v6_28:0xc.d = v0_91:0xc.d u>> 0x1f
v0_91.d <<= 1
v0_91:4.d <<= 1
v0_91:8.d <<= 1
v0_91:0xc.d <<= 1
int32_t temp0_50 = x8_2[0x36]
uint128_t v2_62
v2_62.d = temp0_50
v2_62:4.d = temp0_50
v2_62:8.d = temp0_50
v2_62:0xc.d = temp0_50
uint128_t v0_92 = vorrq_s8(v0_91, v6_28)
v6_28.d = v5_56.d u>> 0x19
v6_28:4.d = v5_56:4.d u>> 0x19
v6_28:8.d = v5_56:8.d u>> 0x19
v6_28:0xc.d = v5_56:0xc.d u>> 0x19
v5_56.d <<= 7
v5_56:4.d <<= 7
v5_56:8.d <<= 7
v5_56:0xc.d <<= 7
uint128_t v5_57 = vorrq_s8(v5_56, v6_28)
int32_t temp0_51 = x8_2[0x37]
v6_28.d = temp0_51
v6_28:4.d = temp0_51
v6_28:8.d = temp0_51
v6_28:0xc.d = temp0_51
uint128_t v3_57 = v0_92 ^ v3_56
uint128_t v7_30 = v0_92 ^ v7_29
uint128_t v6_29 = v5_57 ^ v6_28
v0_92.d <<= 7
v0_92:4.d <<= 7
v0_92:8.d <<= 7
v0_92:0xc.d <<= 7
uint128_t v3_58 = v3_57 ^ v5_57
uint128_t v0_93 = v5_57 ^ v1_80 ^ v0_92
uint128_t v1_83 = v2_62 ^ not.o(v6_29)
v2_62.d = v3_58.d u>> 0x1b
v2_62:4.d = v3_58:4.d u>> 0x1b
v2_62:8.d = v3_58:8.d u>> 0x1b
v2_62:0xc.d = v3_58:0xc.d u>> 0x1b
v3_58.d <<= 5
v3_58:4.d <<= 5
v3_58:8.d <<= 5
v3_58:0xc.d <<= 5
uint128_t v2_63 = vorrq_s8(v3_58, v2_62)
v3_58.d = v0_93.d u>> 0xa
v3_58:4.d = v0_93:4.d u>> 0xa
v3_58:8.d = v0_93:8.d u>> 0xa
v3_58:0xc.d = v0_93:0xc.d u>> 0xa
v0_93.d <<= 0x16
v0_93:4.d <<= 0x16
v0_93:8.d <<= 0x16
v0_93:0xc.d <<= 0x16
uint128_t v2_64 = v7_30 ^ v4_45 ^ v2_63
uint128_t v4_47 = v6_29 ^ v7_30
uint128_t v0_95 = v1_83 ^ vorrq_s8(v0_93, v3_58)
uint128_t v4_48 = vorrq_s8(v0_95, v4_47)
uint128_t v0_96 = (v2_64 & v4_47) ^ v0_95
uint128_t v6_30 = v0_96 & not.o(v6_29)
uint128_t v1_86 = v4_48 ^ v7_30 ^ v0_96
v7_30.d = v0_96.d u>> 0x13
v7_30:4.d = v0_96:4.d u>> 0x13
v7_30:8.d = v0_96:8.d u>> 0x13
v7_30:0xc.d = v0_96:0xc.d u>> 0x13
v0_96.d <<= 0xd
v0_96:4.d <<= 0xd
v0_96:8.d <<= 0xd
v0_96:0xc.d <<= 0xd
uint128_t v6_31 = v6_30 ^ v2_64
uint128_t v0_97 = vorrq_s8(v0_96, v7_30)
uint128_t v2_66 = (v6_31 & v2_64) ^ not.o(v1_86)
uint128_t v7_31
v7_31.d = v0_97.d << 3
v7_31:4.d = v0_97:4.d << 3
v7_31:8.d = v0_97:8.d << 3
v7_31:0xc.d = v0_97:0xc.d << 3
uint128_t v4_50
v4_50.d = v2_66.d u>> 0x1d
v4_50:4.d = v2_66:4.d u>> 0x1d
v4_50:8.d = v2_66:8.d u>> 0x1d
v4_50:0xc.d = v2_66:0xc.d u>> 0x1d
v2_66.d <<= 3
v2_66:4.d <<= 3
v2_66:8.d <<= 3
v2_66:0xc.d <<= 3
int32_t temp0_52 = x8_2[0x38]
v5_57.d = temp0_52
v5_57:4.d = temp0_52
v5_57:8.d = temp0_52
v5_57:0xc.d = temp0_52
uint128_t v2_67 = vorrq_s8(v2_66, v4_50)
int32_t temp0_53 = x8_2[0x39]
v3_58.d = temp0_53
v3_58:4.d = temp0_53
v3_58:8.d = temp0_53
v3_58:0xc.d = temp0_53
uint128_t v4_51 = v6_31 ^ v0_97 ^ v2_67
uint128_t v1_90 = not.o(v4_48 ^ v2_64 ^ v7_31 ^ (v6_31 | not.o(v1_86)) ^ v2_67)
uint128_t v6_32
v6_32.d = v4_51.d u>> 0x1f
v6_32:4.d = v4_51:4.d u>> 0x1f
v6_32:8.d = v4_51:8.d u>> 0x1f
v6_32:0xc.d = v4_51:0xc.d u>> 0x1f
v4_51.d <<= 1
v4_51:4.d <<= 1
v4_51:8.d <<= 1
v4_51:0xc.d <<= 1
uint128_t v4_52 = vorrq_s8(v4_51, v6_32)
v6_32.d = v1_90.d u>> 0x19
v6_32:4.d = v1_90:4.d u>> 0x19
v6_32:8.d = v1_90:8.d u>> 0x19
v6_32:0xc.d = v1_90:0xc.d u>> 0x19
v1_90.d <<= 7
v1_90:4.d <<= 7
v1_90:8.d <<= 7
v1_90:0xc.d <<= 7
int32_t temp0_54 = x8_2[0x3a]
v7_31.d = temp0_54
v7_31:4.d = temp0_54
v7_31:8.d = temp0_54
v7_31:0xc.d = temp0_54
uint128_t v1_91 = vorrq_s8(v1_90, v6_32)
int32_t temp0_55 = x8_2[0x3b]
v6_32.d = temp0_55
v6_32:4.d = temp0_55
v6_32:8.d = temp0_55
v6_32:0xc.d = temp0_55
uint128_t v0_99 = v4_52 ^ v0_97 ^ v1_91
uint128_t v3_59 = v4_52 ^ v3_58
v4_52.d <<= 7
v4_52:4.d <<= 7
v4_52:8.d <<= 7
v4_52:0xc.d <<= 7
uint128_t v2_69 = v1_91 ^ v2_67 ^ v4_52
v4_52.d = v0_99.d u>> 0x1b
v4_52:4.d = v0_99:4.d u>> 0x1b
v4_52:8.d = v0_99:8.d u>> 0x1b
v4_52:0xc.d = v0_99:0xc.d u>> 0x1b
v0_99.d <<= 5
v0_99:4.d <<= 5
v0_99:8.d <<= 5
v0_99:0xc.d <<= 5
uint128_t v0_100 = vorrq_s8(v0_99, v4_52)
v4_52.d = v2_69.d u>> 0xa
v4_52:4.d = v2_69:4.d u>> 0xa
v4_52:8.d = v2_69:8.d u>> 0xa
v4_52:0xc.d = v2_69:0xc.d u>> 0xa
v2_69.d <<= 0x16
v2_69:4.d <<= 0x16
v2_69:8.d <<= 0x16
v2_69:0xc.d <<= 0x16
uint128_t v6_33 = v1_91 ^ v6_32
uint128_t v0_101 = v0_100 ^ v5_57
uint128_t v2_71 = vorrq_s8(v2_69, v4_52) ^ v7_31
uint128_t v5_58 = v0_101 & v6_33
uint128_t v7_33 = v5_58 ^ not.o(v2_71)
uint128_t v0_102 = v0_101 ^ v6_33
uint128_t v3_60 = v3_59 ^ v7_33
uint128_t v0_103 = vorrq_s8(v3_60, v0_102)
uint128_t v2_74 = (v6_33 | not.o(v2_71)) ^ v0_102 ^ v3_60
uint128_t v6_35 = vorrq_s8(v0_103, v7_33) ^ v2_74
uint128_t v0_105 = v7_33 ^ v6_33 ^ v0_103 ^ v6_35
uint128_t v7_34
v7_34.d = v6_35.d u>> 0x13
v7_34:4.d = v6_35:4.d u>> 0x13
v7_34:8.d = v6_35:8.d u>> 0x13
v7_34:0xc.d = v6_35:0xc.d u>> 0x13
v6_35.d <<= 0xd
v6_35:4.d <<= 0xd
v6_35:8.d <<= 0xd
v6_35:0xc.d <<= 0xd
uint128_t v2_75 = v0_105 & v2_74
uint128_t v6_36 = vorrq_s8(v6_35, v7_34)
v7_34.d = v0_105.d u>> 0x1d
v7_34:4.d = v0_105:4.d u>> 0x1d
v7_34:8.d = v0_105:8.d u>> 0x1d
v7_34:0xc.d = v0_105:0xc.d u>> 0x1d
v0_105.d <<= 3
v0_105:4.d <<= 3
v0_105:8.d <<= 3
v0_105:0xc.d <<= 3
uint128_t v0_106 = vorrq_s8(v0_105, v7_34)
v7_34.d = v6_36.d << 3
v7_34:4.d = v6_36:4.d << 3
v7_34:8.d = v6_36:8.d << 3
v7_34:0xc.d = v6_36:0xc.d << 3
int32_t temp0_56 = x8_2[0x3c]
v1_91.d = temp0_56
v1_91:4.d = temp0_56
v1_91:8.d = temp0_56
v1_91:0xc.d = temp0_56
uint128_t v3_62 = v6_36 ^ v3_60 ^ v0_106
int32_t temp0_57 = x8_2[0x3d]
v4_52.d = temp0_57
v4_52:4.d = temp0_57
v4_52:8.d = temp0_57
v4_52:0xc.d = temp0_57
uint128_t v2_76 = v5_58 ^ v2_71 ^ v7_34 ^ v0_106 ^ v2_75
uint128_t v5_61
v5_61.d = v3_62.d u>> 0x1f
v5_61:4.d = v3_62:4.d u>> 0x1f
v5_61:8.d = v3_62:8.d u>> 0x1f
v5_61:0xc.d = v3_62:0xc.d u>> 0x1f
v3_62.d <<= 1
v3_62:4.d <<= 1
v3_62:8.d <<= 1
v3_62:0xc.d <<= 1
int32_t temp0_58 = x8_2[0x3e]
v7_34.d = temp0_58
v7_34:4.d = temp0_58
v7_34:8.d = temp0_58
v7_34:0xc.d = temp0_58
uint128_t v3_63 = vorrq_s8(v3_62, v5_61)
v5_61.d = v2_76.d u>> 0x19
v5_61:4.d = v2_76:4.d u>> 0x19
v5_61:8.d = v2_76:8.d u>> 0x19
v5_61:0xc.d = v2_76:0xc.d u>> 0x19
v2_76.d <<= 7
v2_76:4.d <<= 7
v2_76:8.d <<= 7
v2_76:0xc.d <<= 7
uint128_t v2_77 = vorrq_s8(v2_76, v5_61)
int32_t temp0_59 = x8_2[0x3f]
v5_61.d = temp0_59
v5_61:4.d = temp0_59
v5_61:8.d = temp0_59
v5_61:0xc.d = temp0_59
uint128_t v6_38 = v3_63 ^ v6_36 ^ v2_77
uint128_t v4_53 = v3_63 ^ v4_52
v3_63.d <<= 7
v3_63:4.d <<= 7
v3_63:8.d <<= 7
v3_63:0xc.d <<= 7
uint128_t v2_78 = v2_77 ^ v5_61
uint128_t v3_64 = v2_77 ^ v0_106 ^ v3_63
v5_61.d = v6_38.d u>> 0x1b
v5_61:4.d = v6_38:4.d u>> 0x1b
v5_61:8.d = v6_38:8.d u>> 0x1b
v5_61:0xc.d = v6_38:0xc.d u>> 0x1b
v6_38.d <<= 5
v6_38:4.d <<= 5
v6_38:8.d <<= 5
v6_38:0xc.d <<= 5
uint128_t v5_62 = vorrq_s8(v6_38, v5_61)
v6_38.d = v3_64.d u>> 0xa
v6_38:4.d = v3_64:4.d u>> 0xa
v6_38:8.d = v3_64:8.d u>> 0xa
v6_38:0xc.d = v3_64:0xc.d u>> 0xa
v3_64.d <<= 0x16
v3_64:4.d <<= 0x16
v3_64:8.d <<= 0x16
v3_64:0xc.d <<= 0x16
uint128_t v5_63 = v5_62 ^ v1_91
uint128_t v1_92 = vorrq_s8(v3_64, v6_38) ^ v7_34
uint128_t v3_67 = vorrq_s8(v1_92, v4_53) ^ v2_78
uint128_t v7_36 = v3_67 ^ v1_92
uint128_t v1_93 = vorrq_s8(v1_92 ^ v4_53, v2_78) & v5_63
uint128_t v2_80 = v3_67 ^ v4_53
uint128_t v4_55 = v2_80 ^ v5_63 ^ vorrq_s8(v3_67, v4_53)
uint128_t v5_65 = vorrq_s8(v2_80, v5_63) ^ v7_36
uint128_t v4_57 = (v4_55 & v5_65) ^ v2_80
uint128_t v2_81 = (v5_65 | not.o(v7_36 ^ v4_55)) ^ v2_80
uint128_t v7_38
v7_38.d = v4_57.d u>> 0x1d
v7_38:4.d = v4_57:4.d u>> 0x1d
v7_38:8.d = v4_57:8.d u>> 0x1d
v7_38:0xc.d = v4_57:0xc.d u>> 0x1d
v4_57.d <<= 3
v4_57:4.d <<= 3
v4_57:8.d <<= 3
v4_57:0xc.d <<= 3
uint128_t v4_58 = vorrq_s8(v4_57, v7_38)
v7_38.d = v2_81.d u>> 0x13
v7_38:4.d = v2_81:4.d u>> 0x13
v7_38:8.d = v2_81:8.d u>> 0x13
v7_38:0xc.d = v2_81:0xc.d u>> 0x13
v2_81.d <<= 0xd
v2_81:4.d <<= 0xd
v2_81:8.d <<= 0xd
v2_81:0xc.d <<= 0xd
uint128_t v2_82 = vorrq_s8(v2_81, v7_38)
int32_t temp0_60 = x8_2[0x40]
v0_106.d = temp0_60
v0_106:4.d = temp0_60
v0_106:8.d = temp0_60
v0_106:0xc.d = temp0_60
uint128_t v3_70 = v1_93 ^ v3_67 ^ v4_58 ^ v2_82
v7_38.d = v2_82.d << 3
v7_38:4.d = v2_82:4.d << 3
v7_38:8.d = v2_82:8.d << 3
v7_38:0xc.d = v2_82:0xc.d << 3
int32_t temp0_61 = x8_2[0x41]
v6_38.d = temp0_61
v6_38:4.d = temp0_61
v6_38:8.d = temp0_61
v6_38:0xc.d = temp0_61
uint128_t v5_67 = v4_58 ^ v5_65 ^ v7_38
v7_38.d = v3_70.d u>> 0x1f
v7_38:4.d = v3_70:4.d u>> 0x1f
v7_38:8.d = v3_70:8.d u>> 0x1f
v7_38:0xc.d = v3_70:0xc.d u>> 0x1f
v3_70.d <<= 1
v3_70:4.d <<= 1
v3_70:8.d <<= 1
v3_70:0xc.d <<= 1
int32_t temp0_62 = x8_2[0x42]
uint128_t v1_94
v1_94.d = temp0_62
v1_94:4.d = temp0_62
v1_94:8.d = temp0_62
v1_94:0xc.d = temp0_62
uint128_t v3_71 = vorrq_s8(v3_70, v7_38)
v7_38.d = v5_67.d u>> 0x19
v7_38:4.d = v5_67:4.d u>> 0x19
v7_38:8.d = v5_67:8.d u>> 0x19
v7_38:0xc.d = v5_67:0xc.d u>> 0x19
v5_67.d <<= 7
v5_67:4.d <<= 7
v5_67:8.d <<= 7
v5_67:0xc.d <<= 7
uint128_t v5_68 = vorrq_s8(v5_67, v7_38)
int32_t temp0_63 = x8_2[0x43]
v7_38.d = temp0_63
v7_38:4.d = temp0_63
v7_38:8.d = temp0_63
v7_38:0xc.d = temp0_63
uint128_t v16_4 = v3_71 ^ v2_82
v2_82.d = v3_71.d << 7
v2_82:4.d = v3_71:4.d << 7
v2_82:8.d = v3_71:8.d << 7
v2_82:0xc.d = v3_71:0xc.d << 7
uint128_t v6_39 = v3_71 ^ v6_38
uint128_t v4_59 = v16_4 ^ v5_68
uint128_t v7_39 = v5_68 ^ v7_38
uint128_t v3_73 = v2_82 ^ v4_58 ^ v5_68
v5_68.d = v4_59.d u>> 0x1b
v5_68:4.d = v4_59:4.d u>> 0x1b
v5_68:8.d = v4_59:8.d u>> 0x1b
v5_68:0xc.d = v4_59:0xc.d u>> 0x1b
v4_59.d <<= 5
v4_59:4.d <<= 5
v4_59:8.d <<= 5
v4_59:0xc.d <<= 5
uint128_t v4_60 = vorrq_s8(v4_59, v5_68)
v5_68.d = v3_73.d u>> 0xa
v5_68:4.d = v3_73:4.d u>> 0xa
v5_68:8.d = v3_73:8.d u>> 0xa
v5_68:0xc.d = v3_73:0xc.d u>> 0xa
v3_73.d <<= 0x16
v3_73:4.d <<= 0x16
v3_73:8.d <<= 0x16
v3_73:0xc.d <<= 0x16
uint128_t v0_107 = v4_60 ^ v0_106
uint128_t v4_61 = v0_107 ^ v7_39
uint128_t v1_95 = vorrq_s8(v3_73, v5_68) ^ v1_94
uint128_t v6_40 = v1_95 ^ v6_39
uint128_t v0_108 = (v4_61 & v6_39) ^ v0_107
uint128_t v7_41 = v4_61 ^ v1_95
uint128_t v5_71 = vorrq_s8(v0_107, v7_39) ^ v6_40
uint128_t v4_62 = v4_61 ^ v6_40
uint128_t v1_97 = vorrq_s8(v0_108, v1_95) ^ v4_62
int128_t v4_64 = (v0_108 | not.o(v4_62)) ^ vorrq_s8(v5_71, v7_41)
uint128_t v0_109 = v4_64 ^ v7_41 ^ v0_108
uint128_t v7_42
v7_42.d = v1_97.d u>> 0x1d
v7_42:4.d = v1_97:4.d u>> 0x1d
v7_42:8.d = v1_97:8.d u>> 0x1d
v7_42:0xc.d = v1_97:0xc.d u>> 0x1d
v1_97.d <<= 3
v1_97:4.d <<= 3
v1_97:8.d <<= 3
v1_97:0xc.d <<= 3
uint128_t v1_98 = vorrq_s8(v1_97, v7_42)
v7_42.d = v0_109.d u>> 0x13
v7_42:4.d = v0_109:4.d u>> 0x13
v7_42:8.d = v0_109:8.d u>> 0x13
v7_42:0xc.d = v0_109:0xc.d u>> 0x13
v0_109.d <<= 0xd
v0_109:4.d <<= 0xd
v0_109:8.d <<= 0xd
v0_109:0xc.d <<= 0xd
uint128_t v0_110 = vorrq_s8(v0_109, v7_42)
int32_t temp0_64 = x8_2[0x45]
v2_82.d = temp0_64
v2_82:4.d = temp0_64
v2_82:8.d = temp0_64
v2_82:0xc.d = temp0_64
int128_t v4_66 = v4_64 ^ v1_98 ^ v0_110
v7_42.d = v0_110.d << 3
v7_42:4.d = v0_110:4.d << 3
v7_42:8.d = v0_110:8.d << 3
v7_42:0xc.d = v0_110:0xc.d << 3
uint128_t v5_73 = v1_98 ^ v5_71 ^ v7_42
v7_42.d = v4_66.d u>> 0x1f
v7_42:4.d = v4_66:4.d u>> 0x1f
v7_42:8.d = v4_66:8.d u>> 0x1f
v7_42:0xc.d = v4_66:0xc.d u>> 0x1f
v4_66.d <<= 1
v4_66:4.d <<= 1
v4_66:8.d <<= 1
v4_66:0xc.d <<= 1
int32_t temp0_65 = x8_2[0x47]
v3_73.d = temp0_65
v3_73:4.d = temp0_65
v3_73:8.d = temp0_65
v3_73:0xc.d = temp0_65
int128_t v6_41
v6_41.d = x8_2[0x44]
uint128_t v4_67 = vorrq_s8(v4_66, v7_42)
v7_42.d = v5_73.d u>> 0x19
v7_42:4.d = v5_73:4.d u>> 0x19
v7_42:8.d = v5_73:8.d u>> 0x19
v7_42:0xc.d = v5_73:0xc.d u>> 0x19
v5_73.d <<= 7
v5_73:4.d <<= 7
v5_73:8.d <<= 7
v5_73:0xc.d <<= 7
uint128_t v5_74 = vorrq_s8(v5_73, v7_42)
v7_42.d = x8_2[0x46]
uint128_t v0_111 = v4_67 ^ v0_110
uint128_t v2_83 = v4_67 ^ v2_82
v4_67.d <<= 7
v4_67:4.d <<= 7
v4_67:8.d <<= 7
v4_67:0xc.d <<= 7
uint128_t v0_112 = v0_111 ^ v5_74
uint128_t v3_74 = v5_74 ^ v3_73
uint128_t v1_100 = v4_67 ^ v1_98 ^ v5_74
v5_74.d = v0_112.d u>> 0x1b
v5_74:4.d = v0_112:4.d u>> 0x1b
v5_74:8.d = v0_112:8.d u>> 0x1b
v5_74:0xc.d = v0_112:0xc.d u>> 0x1b
v0_112.d <<= 5
v0_112:4.d <<= 5
v0_112:8.d <<= 5
v0_112:0xc.d <<= 5
uint128_t v6_43 = vdupq_laneq_s32(not.o(v6_41), 0)
uint128_t v0_113 = vorrq_s8(v0_112, v5_74)
v5_74.d = v1_100.d u>> 0xa
v5_74:4.d = v1_100:4.d u>> 0xa
v5_74:8.d = v1_100:8.d u>> 0xa
v5_74:0xc.d = v1_100:0xc.d u>> 0xa
v1_100.d <<= 0x16
v1_100:4.d <<= 0x16
v1_100:8.d <<= 0x16
v1_100:0xc.d <<= 0x16
uint128_t v0_114 = v6_43 ^ v0_113
uint128_t v5_75 = v0_114 & v2_83
uint128_t v1_103 = vdupq_laneq_s32(not.o(v7_42), 0) ^ vorrq_s8(v1_100, v5_74) ^ v5_75
uint128_t v5_76 = vorrq_s8(v5_75, v3_74)
uint128_t v2_84 = v5_76 ^ v2_83
uint128_t v5_77 = v5_76 ^ v0_114
uint128_t v3_75 = v1_103 ^ v3_74
uint128_t v0_115 = vorrq_s8(v2_84, v0_114)
uint128_t v2_85 = v3_75 ^ v2_84
v6_43.d = v3_75.d u>> 0x1d
v6_43:4.d = v3_75:4.d u>> 0x1d
v6_43:8.d = v3_75:8.d u>> 0x1d
v6_43:0xc.d = v3_75:0xc.d u>> 0x1d
v3_75.d <<= 3
v3_75:4.d <<= 3
v3_75:8.d <<= 3
v3_75:0xc.d <<= 3
uint128_t v1_105 = vorrq_s8(v5_77, v1_103) & v0_115
uint128_t v3_76 = vorrq_s8(v3_75, v6_43)
v6_43.d = v1_105.d u>> 0x13
v6_43:4.d = v1_105:4.d u>> 0x13
v6_43:8.d = v1_105:8.d u>> 0x13
v6_43:0xc.d = v1_105:0xc.d u>> 0x13
uint128_t v7_44
v7_44.d = v1_105.d << 0xd
v7_44:4.d = v1_105:4.d << 0xd
v7_44:8.d = v1_105:8.d << 0xd
v7_44:0xc.d = v1_105:0xc.d << 0xd
uint128_t v6_44 = vorrq_s8(v7_44, v6_43)
uint128_t v5_78 = v2_85 ^ v5_77
int32_t temp0_66 = x8_2[0x48]
v4_67.d = temp0_66
v4_67:4.d = temp0_66
v4_67:8.d = temp0_66
v4_67:0xc.d = temp0_66
uint128_t v0_118 = v0_115 ^ v3_76 ^ v6_44 ^ (v1_105 & v5_78)
uint128_t v1_106
v1_106.d = v6_44.d << 3
v1_106:4.d = v6_44:4.d << 3
v1_106:8.d = v6_44:8.d << 3
v1_106:0xc.d = v6_44:0xc.d << 3
int32_t temp0_67 = x8_2[0x49]
v7_44.d = temp0_67
v7_44:4.d = temp0_67
v7_44:8.d = temp0_67
v7_44:0xc.d = temp0_67
uint128_t v1_107 = v5_78 ^ v3_76 ^ (v1_105 & v2_85) ^ v1_106
uint128_t v2_87
v2_87.d = v0_118.d u>> 0x1f
v2_87:4.d = v0_118:4.d u>> 0x1f
v2_87:8.d = v0_118:8.d u>> 0x1f
v2_87:0xc.d = v0_118:0xc.d u>> 0x1f
v0_118.d <<= 1
v0_118:4.d <<= 1
v0_118:8.d <<= 1
v0_118:0xc.d <<= 1
int32_t temp0_68 = x8_2[0x4a]
uint128_t v5_79
v5_79.d = temp0_68
v5_79:4.d = temp0_68
v5_79:8.d = temp0_68
v5_79:0xc.d = temp0_68
uint128_t v0_119 = vorrq_s8(v0_118, v2_87)
v2_87.d = v1_107.d u>> 0x19
v2_87:4.d = v1_107:4.d u>> 0x19
v2_87:8.d = v1_107:8.d u>> 0x19
v2_87:0xc.d = v1_107:0xc.d u>> 0x19
v1_107.d <<= 7
v1_107:4.d <<= 7
v1_107:8.d <<= 7
v1_107:0xc.d <<= 7
uint128_t v1_108 = vorrq_s8(v1_107, v2_87)
int32_t temp0_69 = x8_2[0x4b]
v2_87.d = temp0_69
v2_87:4.d = temp0_69
v2_87:8.d = temp0_69
v2_87:0xc.d = temp0_69
uint128_t v7_45 = v0_119 ^ v7_44
uint128_t v2_88 = v1_108 ^ v2_87
uint128_t v1_109 = v0_119 ^ v6_44 ^ v1_108
v0_119.d <<= 7
v0_119:4.d <<= 7
v0_119:8.d <<= 7
v0_119:0xc.d <<= 7
uint128_t v0_120 = v1_108 ^ v3_76 ^ v0_119
uint128_t v3_77
v3_77.d = v1_109.d u>> 0x1b
v3_77:4.d = v1_109:4.d u>> 0x1b
v3_77:8.d = v1_109:8.d u>> 0x1b
v3_77:0xc.d = v1_109:0xc.d u>> 0x1b
v1_109.d <<= 5
v1_109:4.d <<= 5
v1_109:8.d <<= 5
v1_109:0xc.d <<= 5
uint128_t v1_110 = vorrq_s8(v1_109, v3_77)
v3_77.d = v0_120.d u>> 0xa
v3_77:4.d = v0_120:4.d u>> 0xa
v3_77:8.d = v0_120:8.d u>> 0xa
v3_77:0xc.d = v0_120:0xc.d u>> 0xa
v0_120.d <<= 0x16
v0_120:4.d <<= 0x16
v0_120:8.d <<= 0x16
v0_120:0xc.d <<= 0x16
uint128_t v1_111 = v1_110 ^ v4_67
uint128_t v0_122 = vorrq_s8(v0_120, v3_77) ^ v5_79
uint128_t v5_81 = (v0_122 & v1_111) ^ v2_88
uint128_t v0_124 = v0_122 ^ v7_45 ^ v5_81
uint128_t v2_90 = vorrq_s8(v1_111, v2_88) ^ v7_45
uint128_t v1_112 = v0_124 ^ v1_111
v7_45.d = v0_124.d u>> 0x13
v7_45:4.d = v0_124:4.d u>> 0x13
v7_45:8.d = v0_124:8.d u>> 0x13
v7_45:0xc.d = v0_124:0xc.d u>> 0x13
v0_124.d <<= 0xd
v0_124:4.d <<= 0xd
v0_124:8.d <<= 0xd
v0_124:0xc.d <<= 0xd
uint128_t v0_125 = vorrq_s8(v0_124, v7_45)
uint128_t v7_47 = v1_112 ^ (v5_81 & v2_90)
uint128_t v1_114 = vorrq_s8(v1_112, v2_90) ^ v5_81
v5_81.d = v0_125.d << 3
v5_81:4.d = v0_125:4.d << 3
v5_81:8.d = v0_125:8.d << 3
v5_81:0xc.d = v0_125:0xc.d << 3
uint128_t v2_92 = v7_47 ^ v2_90 ^ v1_114
uint128_t v5_82 = v5_81 ^ v7_47
v7_47.d = v2_92.d u>> 0x1d
v7_47:4.d = v2_92:4.d u>> 0x1d
v7_47:8.d = v2_92:8.d u>> 0x1d
v7_47:0xc.d = v2_92:0xc.d u>> 0x1d
v2_92.d <<= 3
v2_92:4.d <<= 3
v2_92:8.d <<= 3
v2_92:0xc.d <<= 3
int32_t temp0_70 = x8_2[0x4c]
uint128_t v6_45
v6_45.d = temp0_70
v6_45:4.d = temp0_70
v6_45:8.d = temp0_70
v6_45:0xc.d = temp0_70
uint128_t v2_93 = vorrq_s8(v2_92, v7_47)
int32_t temp0_71 = x8_2[0x4d]
v3_77.d = temp0_71
v3_77:4.d = temp0_71
v3_77:8.d = temp0_71
v3_77:0xc.d = temp0_71
uint128_t v1_116 = v1_114 ^ v0_125 ^ v2_93
uint128_t v5_84 = not.o(v5_82 ^ v2_93)
v7_47.d = v1_116.d u>> 0x1f
v7_47:4.d = v1_116:4.d u>> 0x1f
v7_47:8.d = v1_116:8.d u>> 0x1f
v7_47:0xc.d = v1_116:0xc.d u>> 0x1f
v1_116.d <<= 1
v1_116:4.d <<= 1
v1_116:8.d <<= 1
v1_116:0xc.d <<= 1
uint128_t v1_117 = vorrq_s8(v1_116, v7_47)
v7_47.d = v5_84.d u>> 0x19
v7_47:4.d = v5_84:4.d u>> 0x19
v7_47:8.d = v5_84:8.d u>> 0x19
v7_47:0xc.d = v5_84:0xc.d u>> 0x19
v5_84.d <<= 7
v5_84:4.d <<= 7
v5_84:8.d <<= 7
v5_84:0xc.d <<= 7
int32_t temp0_72 = x8_2[0x4e]
v4_67.d = temp0_72
v4_67:4.d = temp0_72
v4_67:8.d = temp0_72
v4_67:0xc.d = temp0_72
uint128_t v5_85 = vorrq_s8(v5_84, v7_47)
int32_t temp0_73 = x8_2[0x4f]
v7_47.d = temp0_73
v7_47:4.d = temp0_73
v7_47:8.d = temp0_73
v7_47:0xc.d = temp0_73
uint128_t v0_127 = v1_117 ^ v0_125 ^ v5_85
uint128_t v3_78 = v1_117 ^ v3_77
v1_117.d <<= 7
v1_117:4.d <<= 7
v1_117:8.d <<= 7
v1_117:0xc.d <<= 7
uint128_t v1_118 = v5_85 ^ v2_93 ^ v1_117
uint128_t v2_94
v2_94.d = v0_127.d u>> 0x1b
v2_94:4.d = v0_127:4.d u>> 0x1b
v2_94:8.d = v0_127:8.d u>> 0x1b
v2_94:0xc.d = v0_127:0xc.d u>> 0x1b
v0_127.d <<= 5
v0_127:4.d <<= 5
v0_127:8.d <<= 5
v0_127:0xc.d <<= 5
uint128_t v0_128 = vorrq_s8(v0_127, v2_94)
v2_94.d = v1_118.d u>> 0xa
v2_94:4.d = v1_118:4.d u>> 0xa
v2_94:8.d = v1_118:8.d u>> 0xa
v2_94:0xc.d = v1_118:0xc.d u>> 0xa
v1_118.d <<= 0x16
v1_118:4.d <<= 0x16
v1_118:8.d <<= 0x16
v1_118:0xc.d <<= 0x16
uint128_t v5_86 = v5_85 ^ v7_47
uint128_t v0_129 = v0_128 ^ v6_45
uint128_t v1_120 = vorrq_s8(v1_118, v2_94) ^ v4_67
uint128_t v2_95 = v5_86 ^ v3_78
uint128_t v4_68 = vorrq_s8(v0_129, v5_86)
uint128_t v3_79 = v0_129 & v3_78
uint128_t v0_130 = v1_120 ^ v0_129
uint128_t v1_121 = v1_120 ^ v2_95
uint128_t v2_97 = vorrq_s8(v3_79, v0_130) ^ (v4_68 & v2_95)
uint128_t v4_69 = v3_79 ^ v4_68
uint128_t v0_132 = (v4_69 & v0_130) ^ v1_121
uint128_t v1_122 = vorrq_s8(v2_97 ^ v3_79, v4_69) ^ v1_121
uint128_t v5_87
v5_87.d = v2_97.d u>> 0x1d
v5_87:4.d = v2_97:4.d u>> 0x1d
v5_87:8.d = v2_97:8.d u>> 0x1d
v5_87:0xc.d = v2_97:0xc.d u>> 0x1d
v6_45.d = v2_97.d << 3
v6_45:4.d = v2_97:4.d << 3
v6_45:8.d = v2_97:8.d << 3
v6_45:0xc.d = v2_97:0xc.d << 3
uint128_t v2_99 = (v1_122 & not.o(v2_97)) ^ v4_69
uint128_t v5_88 = vorrq_s8(v6_45, v5_87)
v4_69.d = v2_99.d u>> 0x13
v4_69:4.d = v2_99:4.d u>> 0x13
v4_69:8.d = v2_99:8.d u>> 0x13
v4_69:0xc.d = v2_99:0xc.d u>> 0x13
v2_99.d <<= 0xd
v2_99:4.d <<= 0xd
v2_99:8.d <<= 0xd
v2_99:0xc.d <<= 0xd
uint128_t v2_100 = vorrq_s8(v2_99, v4_69)
int32_t temp0_74 = x8_2[0x50]
v7_47.d = temp0_74
v7_47:4.d = temp0_74
v7_47:8.d = temp0_74
v7_47:0xc.d = temp0_74
uint128_t v1_124 = v1_122 ^ v5_88 ^ v2_100
v4_69.d = v2_100.d << 3
v4_69:4.d = v2_100:4.d << 3
v4_69:8.d = v2_100:8.d << 3
v4_69:0xc.d = v2_100:0xc.d << 3
int32_t temp0_75 = x8_2[0x51]
v6_45.d = temp0_75
v6_45:4.d = temp0_75
v6_45:8.d = temp0_75
v6_45:0xc.d = temp0_75
uint128_t v0_134 = v0_132 ^ v5_88 ^ v4_69
v4_69.d = v1_124.d u>> 0x1f
v4_69:4.d = v1_124:4.d u>> 0x1f
v4_69:8.d = v1_124:8.d u>> 0x1f
v4_69:0xc.d = v1_124:0xc.d u>> 0x1f
v1_124.d <<= 1
v1_124:4.d <<= 1
v1_124:8.d <<= 1
v1_124:0xc.d <<= 1
int32_t temp0_76 = x8_2[0x52]
uint128_t v3_81
v3_81.d = temp0_76
v3_81:4.d = temp0_76
v3_81:8.d = temp0_76
v3_81:0xc.d = temp0_76
uint128_t v1_125 = vorrq_s8(v1_124, v4_69)
v4_69.d = v0_134.d u>> 0x19
v4_69:4.d = v0_134:4.d u>> 0x19
v4_69:8.d = v0_134:8.d u>> 0x19
v4_69:0xc.d = v0_134:0xc.d u>> 0x19
v0_134.d <<= 7
v0_134:4.d <<= 7
v0_134:8.d <<= 7
v0_134:0xc.d <<= 7
uint128_t v0_135 = vorrq_s8(v0_134, v4_69)
int32_t temp0_77 = x8_2[0x53]
v4_69.d = temp0_77
v4_69:4.d = temp0_77
v4_69:8.d = temp0_77
v4_69:0xc.d = temp0_77
uint128_t v2_102 = v1_125 ^ v2_100 ^ v0_135
uint128_t v6_46 = v1_125 ^ v6_45
v1_125.d <<= 7
v1_125:4.d <<= 7
v1_125:8.d <<= 7
v1_125:0xc.d <<= 7
uint128_t v0_136 = v0_135 ^ v4_69
uint128_t v1_126 = v0_135 ^ v5_88 ^ v1_125
uint128_t v5_89
v5_89.d = v2_102.d u>> 0x1b
v5_89:4.d = v2_102:4.d u>> 0x1b
v5_89:8.d = v2_102:8.d u>> 0x1b
v5_89:0xc.d = v2_102:0xc.d u>> 0x1b
v2_102.d <<= 5
v2_102:4.d <<= 5
v2_102:8.d <<= 5
v2_102:0xc.d <<= 5
uint128_t v5_90 = not.o(v0_136)
uint128_t v5_91 = v7_47 ^ v5_90
v7_47.d = v1_126.d u>> 0xa
v7_47:4.d = v1_126:4.d u>> 0xa
v7_47:8.d = v1_126:8.d u>> 0xa
v7_47:0xc.d = v1_126:0xc.d u>> 0xa
v1_126.d <<= 0x16
v1_126:4.d <<= 0x16
v1_126:8.d <<= 0x16
v1_126:0xc.d <<= 0x16
uint128_t v0_137 = v0_136 ^ v6_46
uint128_t v2_104 = v5_91 ^ vorrq_s8(v2_102, v5_89)
uint128_t v1_128 = v3_81 ^ v5_90 ^ vorrq_s8(v1_126, v7_47)
uint128_t v0_138 = v2_104 ^ v0_137
uint128_t v3_84 = v1_128 ^ (v2_104 & v0_137)
uint128_t v1_129 = v1_128 & v0_138
uint128_t v5_92 = v1_129 ^ not.o(v6_46)
uint128_t v7_49 = v3_84 & not.o(v6_46)
uint128_t v0_139 = vorrq_s8(v3_84, v0_138)
uint128_t v1_130 = v1_129 ^ v6_46
v6_46.d = v3_84.d u>> 0x13
v6_46:4.d = v3_84:4.d u>> 0x13
v6_46:8.d = v3_84:8.d u>> 0x13
v6_46:0xc.d = v3_84:0xc.d u>> 0x13
v3_84.d <<= 0xd
v3_84:4.d <<= 0xd
v3_84:8.d <<= 0xd
v3_84:0xc.d <<= 0xd
uint128_t v3_85 = vorrq_s8(v3_84, v6_46)
uint128_t v6_47 = v7_49 ^ v2_104
uint128_t v1_131 = v1_130 ^ vorrq_s8(v7_49, v2_104)
uint128_t v0_142 = v7_49 ^ v0_139 ^ v3_85 ^ (v6_47 & v5_92)
uint128_t v5_93
v5_93.d = v3_85.d << 3
v5_93:4.d = v3_85:4.d << 3
v5_93:8.d = v3_85:8.d << 3
v5_93:0xc.d = v3_85:0xc.d << 3
uint128_t v5_94 = v6_47 ^ v5_93
v6_47.d = v1_131.d u>> 0x1d
v6_47:4.d = v1_131:4.d u>> 0x1d
v6_47:8.d = v1_131:8.d u>> 0x1d
v6_47:0xc.d = v1_131:0xc.d u>> 0x1d
v1_131.d <<= 3
v1_131:4.d <<= 3
v1_131:8.d <<= 3
v1_131:0xc.d <<= 3
uint128_t v1_132 = vorrq_s8(v1_131, v6_47)
int32_t temp0_78 = x8_2[0x54]
v4_69.d = temp0_78
v4_69:4.d = temp0_78
v4_69:8.d = temp0_78
v4_69:0xc.d = temp0_78
uint128_t v0_143 = v0_142 ^ v1_132
int32_t temp0_79 = x8_2[0x55]
v7_49.d = temp0_79
v7_49:4.d = temp0_79
v7_49:8.d = temp0_79
v7_49:0xc.d = temp0_79
uint128_t v5_95 = v5_94 ^ v1_132
v6_47.d = v0_143.d u>> 0x1f
v6_47:4.d = v0_143:4.d u>> 0x1f
v6_47:8.d = v0_143:8.d u>> 0x1f
v6_47:0xc.d = v0_143:0xc.d u>> 0x1f
v0_143.d <<= 1
v0_143:4.d <<= 1
v0_143:8.d <<= 1
v0_143:0xc.d <<= 1
int32_t temp0_80 = x8_2[0x56]
uint128_t v2_105
v2_105.d = temp0_80
v2_105:4.d = temp0_80
v2_105:8.d = temp0_80
v2_105:0xc.d = temp0_80
uint128_t v0_144 = vorrq_s8(v0_143, v6_47)
v6_47.d = v5_95.d u>> 0x19
v6_47:4.d = v5_95:4.d u>> 0x19
v6_47:8.d = v5_95:8.d u>> 0x19
v6_47:0xc.d = v5_95:0xc.d u>> 0x19
v5_95.d <<= 7
v5_95:4.d <<= 7
v5_95:8.d <<= 7
v5_95:0xc.d <<= 7
uint128_t v5_96 = vorrq_s8(v5_95, v6_47)
int32_t temp0_81 = x8_2[0x57]
v6_47.d = temp0_81
v6_47:4.d = temp0_81
v6_47:8.d = temp0_81
v6_47:0xc.d = temp0_81
uint128_t v3_86 = v0_144 ^ v3_85
uint128_t v7_50 = v0_144 ^ v7_49
uint128_t v6_48 = v5_96 ^ v6_47
v0_144.d <<= 7
v0_144:4.d <<= 7
v0_144:8.d <<= 7
v0_144:0xc.d <<= 7
uint128_t v3_87 = v3_86 ^ v5_96
uint128_t v0_145 = v5_96 ^ v1_132 ^ v0_144
uint128_t v1_135 = v2_105 ^ not.o(v6_48)
v2_105.d = v3_87.d u>> 0x1b
v2_105:4.d = v3_87:4.d u>> 0x1b
v2_105:8.d = v3_87:8.d u>> 0x1b
v2_105:0xc.d = v3_87:0xc.d u>> 0x1b
v3_87.d <<= 5
v3_87:4.d <<= 5
v3_87:8.d <<= 5
v3_87:0xc.d <<= 5
uint128_t v2_106 = vorrq_s8(v3_87, v2_105)
v3_87.d = v0_145.d u>> 0xa
v3_87:4.d = v0_145:4.d u>> 0xa
v3_87:8.d = v0_145:8.d u>> 0xa
v3_87:0xc.d = v0_145:0xc.d u>> 0xa
v0_145.d <<= 0x16
v0_145:4.d <<= 0x16
v0_145:8.d <<= 0x16
v0_145:0xc.d <<= 0x16
uint128_t v2_107 = v7_50 ^ v4_69 ^ v2_106
uint128_t v4_71 = v6_48 ^ v7_50
uint128_t v0_147 = v1_135 ^ vorrq_s8(v0_145, v3_87)
uint128_t v4_72 = vorrq_s8(v0_147, v4_71)
uint128_t v0_148 = (v2_107 & v4_71) ^ v0_147
uint128_t v6_49 = v0_148 & not.o(v6_48)
uint128_t v1_138 = v4_72 ^ v7_50 ^ v0_148
v7_50.d = v0_148.d u>> 0x13
v7_50:4.d = v0_148:4.d u>> 0x13
v7_50:8.d = v0_148:8.d u>> 0x13
v7_50:0xc.d = v0_148:0xc.d u>> 0x13
v0_148.d <<= 0xd
v0_148:4.d <<= 0xd
v0_148:8.d <<= 0xd
v0_148:0xc.d <<= 0xd
uint128_t v6_50 = v6_49 ^ v2_107
uint128_t v0_149 = vorrq_s8(v0_148, v7_50)
uint128_t v2_109 = (v6_50 & v2_107) ^ not.o(v1_138)
uint128_t v7_51
v7_51.d = v0_149.d << 3
v7_51:4.d = v0_149:4.d << 3
v7_51:8.d = v0_149:8.d << 3
v7_51:0xc.d = v0_149:0xc.d << 3
uint128_t v4_74
v4_74.d = v2_109.d u>> 0x1d
v4_74:4.d = v2_109:4.d u>> 0x1d
v4_74:8.d = v2_109:8.d u>> 0x1d
v4_74:0xc.d = v2_109:0xc.d u>> 0x1d
v2_109.d <<= 3
v2_109:4.d <<= 3
v2_109:8.d <<= 3
v2_109:0xc.d <<= 3
int32_t temp0_82 = x8_2[0x58]
v5_96.d = temp0_82
v5_96:4.d = temp0_82
v5_96:8.d = temp0_82
v5_96:0xc.d = temp0_82
uint128_t v2_110 = vorrq_s8(v2_109, v4_74)
int32_t temp0_83 = x8_2[0x59]
v3_87.d = temp0_83
v3_87:4.d = temp0_83
v3_87:8.d = temp0_83
v3_87:0xc.d = temp0_83
uint128_t v4_75 = v6_50 ^ v0_149 ^ v2_110
uint128_t v1_142 = not.o(v4_72 ^ v2_107 ^ v7_51 ^ (v6_50 | not.o(v1_138)) ^ v2_110)
uint128_t v6_51
v6_51.d = v4_75.d u>> 0x1f
v6_51:4.d = v4_75:4.d u>> 0x1f
v6_51:8.d = v4_75:8.d u>> 0x1f
v6_51:0xc.d = v4_75:0xc.d u>> 0x1f
v4_75.d <<= 1
v4_75:4.d <<= 1
v4_75:8.d <<= 1
v4_75:0xc.d <<= 1
uint128_t v4_76 = vorrq_s8(v4_75, v6_51)
v6_51.d = v1_142.d u>> 0x19
v6_51:4.d = v1_142:4.d u>> 0x19
v6_51:8.d = v1_142:8.d u>> 0x19
v6_51:0xc.d = v1_142:0xc.d u>> 0x19
v1_142.d <<= 7
v1_142:4.d <<= 7
v1_142:8.d <<= 7
v1_142:0xc.d <<= 7
int32_t temp0_84 = x8_2[0x5a]
v7_51.d = temp0_84
v7_51:4.d = temp0_84
v7_51:8.d = temp0_84
v7_51:0xc.d = temp0_84
uint128_t v1_143 = vorrq_s8(v1_142, v6_51)
int32_t temp0_85 = x8_2[0x5b]
v6_51.d = temp0_85
v6_51:4.d = temp0_85
v6_51:8.d = temp0_85
v6_51:0xc.d = temp0_85
uint128_t v0_151 = v4_76 ^ v0_149 ^ v1_143
uint128_t v3_88 = v4_76 ^ v3_87
v4_76.d <<= 7
v4_76:4.d <<= 7
v4_76:8.d <<= 7
v4_76:0xc.d <<= 7
uint128_t v2_112 = v1_143 ^ v2_110 ^ v4_76
v4_76.d = v0_151.d u>> 0x1b
v4_76:4.d = v0_151:4.d u>> 0x1b
v4_76:8.d = v0_151:8.d u>> 0x1b
v4_76:0xc.d = v0_151:0xc.d u>> 0x1b
v0_151.d <<= 5
v0_151:4.d <<= 5
v0_151:8.d <<= 5
v0_151:0xc.d <<= 5
uint128_t v0_152 = vorrq_s8(v0_151, v4_76)
v4_76.d = v2_112.d u>> 0xa
v4_76:4.d = v2_112:4.d u>> 0xa
v4_76:8.d = v2_112:8.d u>> 0xa
v4_76:0xc.d = v2_112:0xc.d u>> 0xa
v2_112.d <<= 0x16
v2_112:4.d <<= 0x16
v2_112:8.d <<= 0x16
v2_112:0xc.d <<= 0x16
uint128_t v6_52 = v1_143 ^ v6_51
uint128_t v0_153 = v0_152 ^ v5_96
uint128_t v2_114 = vorrq_s8(v2_112, v4_76) ^ v7_51
uint128_t v5_97 = v0_153 & v6_52
uint128_t v7_53 = v5_97 ^ not.o(v2_114)
uint128_t v0_154 = v0_153 ^ v6_52
uint128_t v3_89 = v3_88 ^ v7_53
uint128_t v0_155 = vorrq_s8(v3_89, v0_154)
uint128_t v2_117 = (v6_52 | not.o(v2_114)) ^ v0_154 ^ v3_89
uint128_t v6_54 = vorrq_s8(v0_155, v7_53) ^ v2_117
uint128_t v0_157 = v7_53 ^ v6_52 ^ v0_155 ^ v6_54
uint128_t v7_54
v7_54.d = v6_54.d u>> 0x13
v7_54:4.d = v6_54:4.d u>> 0x13
v7_54:8.d = v6_54:8.d u>> 0x13
v7_54:0xc.d = v6_54:0xc.d u>> 0x13
v6_54.d <<= 0xd
v6_54:4.d <<= 0xd
v6_54:8.d <<= 0xd
v6_54:0xc.d <<= 0xd
uint128_t v2_118 = v0_157 & v2_117
uint128_t v6_55 = vorrq_s8(v6_54, v7_54)
v7_54.d = v0_157.d u>> 0x1d
v7_54:4.d = v0_157:4.d u>> 0x1d
v7_54:8.d = v0_157:8.d u>> 0x1d
v7_54:0xc.d = v0_157:0xc.d u>> 0x1d
v0_157.d <<= 3
v0_157:4.d <<= 3
v0_157:8.d <<= 3
v0_157:0xc.d <<= 3
uint128_t v0_158 = vorrq_s8(v0_157, v7_54)
v7_54.d = v6_55.d << 3
v7_54:4.d = v6_55:4.d << 3
v7_54:8.d = v6_55:8.d << 3
v7_54:0xc.d = v6_55:0xc.d << 3
int32_t temp0_86 = x8_2[0x5c]
v1_143.d = temp0_86
v1_143:4.d = temp0_86
v1_143:8.d = temp0_86
v1_143:0xc.d = temp0_86
uint128_t v3_91 = v6_55 ^ v3_89 ^ v0_158
int32_t temp0_87 = x8_2[0x5d]
v4_76.d = temp0_87
v4_76:4.d = temp0_87
v4_76:8.d = temp0_87
v4_76:0xc.d = temp0_87
uint128_t v2_119 = v5_97 ^ v2_114 ^ v7_54 ^ v0_158 ^ v2_118
uint128_t v5_100
v5_100.d = v3_91.d u>> 0x1f
v5_100:4.d = v3_91:4.d u>> 0x1f
v5_100:8.d = v3_91:8.d u>> 0x1f
v5_100:0xc.d = v3_91:0xc.d u>> 0x1f
v3_91.d <<= 1
v3_91:4.d <<= 1
v3_91:8.d <<= 1
v3_91:0xc.d <<= 1
int32_t temp0_88 = x8_2[0x5e]
v7_54.d = temp0_88
v7_54:4.d = temp0_88
v7_54:8.d = temp0_88
v7_54:0xc.d = temp0_88
uint128_t v3_92 = vorrq_s8(v3_91, v5_100)
v5_100.d = v2_119.d u>> 0x19
v5_100:4.d = v2_119:4.d u>> 0x19
v5_100:8.d = v2_119:8.d u>> 0x19
v5_100:0xc.d = v2_119:0xc.d u>> 0x19
v2_119.d <<= 7
v2_119:4.d <<= 7
v2_119:8.d <<= 7
v2_119:0xc.d <<= 7
uint128_t v2_120 = vorrq_s8(v2_119, v5_100)
int32_t temp0_89 = x8_2[0x5f]
v5_100.d = temp0_89
v5_100:4.d = temp0_89
v5_100:8.d = temp0_89
v5_100:0xc.d = temp0_89
uint128_t v6_57 = v3_92 ^ v6_55 ^ v2_120
uint128_t v4_77 = v3_92 ^ v4_76
v3_92.d <<= 7
v3_92:4.d <<= 7
v3_92:8.d <<= 7
v3_92:0xc.d <<= 7
uint128_t v2_121 = v2_120 ^ v5_100
uint128_t v3_93 = v2_120 ^ v0_158 ^ v3_92
v5_100.d = v6_57.d u>> 0x1b
v5_100:4.d = v6_57:4.d u>> 0x1b
v5_100:8.d = v6_57:8.d u>> 0x1b
v5_100:0xc.d = v6_57:0xc.d u>> 0x1b
v6_57.d <<= 5
v6_57:4.d <<= 5
v6_57:8.d <<= 5
v6_57:0xc.d <<= 5
uint128_t v5_101 = vorrq_s8(v6_57, v5_100)
v6_57.d = v3_93.d u>> 0xa
v6_57:4.d = v3_93:4.d u>> 0xa
v6_57:8.d = v3_93:8.d u>> 0xa
v6_57:0xc.d = v3_93:0xc.d u>> 0xa
v3_93.d <<= 0x16
v3_93:4.d <<= 0x16
v3_93:8.d <<= 0x16
v3_93:0xc.d <<= 0x16
uint128_t v5_102 = v5_101 ^ v1_143
uint128_t v1_144 = vorrq_s8(v3_93, v6_57) ^ v7_54
uint128_t v3_96 = vorrq_s8(v1_144, v4_77) ^ v2_121
uint128_t v7_56 = v3_96 ^ v1_144
uint128_t v1_145 = vorrq_s8(v1_144 ^ v4_77, v2_121) & v5_102
uint128_t v2_123 = v3_96 ^ v4_77
uint128_t v4_79 = v2_123 ^ v5_102 ^ vorrq_s8(v3_96, v4_77)
uint128_t v5_104 = vorrq_s8(v2_123, v5_102) ^ v7_56
uint128_t v4_81 = (v4_79 & v5_104) ^ v2_123
uint128_t v2_124 = (v5_104 | not.o(v7_56 ^ v4_79)) ^ v2_123
uint128_t v7_58
v7_58.d = v4_81.d u>> 0x1d
v7_58:4.d = v4_81:4.d u>> 0x1d
v7_58:8.d = v4_81:8.d u>> 0x1d
v7_58:0xc.d = v4_81:0xc.d u>> 0x1d
v4_81.d <<= 3
v4_81:4.d <<= 3
v4_81:8.d <<= 3
v4_81:0xc.d <<= 3
uint128_t v4_82 = vorrq_s8(v4_81, v7_58)
v7_58.d = v2_124.d u>> 0x13
v7_58:4.d = v2_124:4.d u>> 0x13
v7_58:8.d = v2_124:8.d u>> 0x13
v7_58:0xc.d = v2_124:0xc.d u>> 0x13
v2_124.d <<= 0xd
v2_124:4.d <<= 0xd
v2_124:8.d <<= 0xd
v2_124:0xc.d <<= 0xd
uint128_t v2_125 = vorrq_s8(v2_124, v7_58)
int32_t temp0_90 = x8_2[0x60]
v0_158.d = temp0_90
v0_158:4.d = temp0_90
v0_158:8.d = temp0_90
v0_158:0xc.d = temp0_90
uint128_t v3_99 = v1_145 ^ v3_96 ^ v4_82 ^ v2_125
v7_58.d = v2_125.d << 3
v7_58:4.d = v2_125:4.d << 3
v7_58:8.d = v2_125:8.d << 3
v7_58:0xc.d = v2_125:0xc.d << 3
int32_t temp0_91 = x8_2[0x61]
v6_57.d = temp0_91
v6_57:4.d = temp0_91
v6_57:8.d = temp0_91
v6_57:0xc.d = temp0_91
uint128_t v5_106 = v4_82 ^ v5_104 ^ v7_58
v7_58.d = v3_99.d u>> 0x1f
v7_58:4.d = v3_99:4.d u>> 0x1f
v7_58:8.d = v3_99:8.d u>> 0x1f
v7_58:0xc.d = v3_99:0xc.d u>> 0x1f
v3_99.d <<= 1
v3_99:4.d <<= 1
v3_99:8.d <<= 1
v3_99:0xc.d <<= 1
int32_t temp0_92 = x8_2[0x62]
uint128_t v1_146
v1_146.d = temp0_92
v1_146:4.d = temp0_92
v1_146:8.d = temp0_92
v1_146:0xc.d = temp0_92
uint128_t v3_100 = vorrq_s8(v3_99, v7_58)
v7_58.d = v5_106.d u>> 0x19
v7_58:4.d = v5_106:4.d u>> 0x19
v7_58:8.d = v5_106:8.d u>> 0x19
v7_58:0xc.d = v5_106:0xc.d u>> 0x19
v5_106.d <<= 7
v5_106:4.d <<= 7
v5_106:8.d <<= 7
v5_106:0xc.d <<= 7
uint128_t v5_107 = vorrq_s8(v5_106, v7_58)
int32_t temp0_93 = x8_2[0x63]
v7_58.d = temp0_93
v7_58:4.d = temp0_93
v7_58:8.d = temp0_93
v7_58:0xc.d = temp0_93
uint128_t v16_6 = v3_100 ^ v2_125
v2_125.d = v3_100.d << 7
v2_125:4.d = v3_100:4.d << 7
v2_125:8.d = v3_100:8.d << 7
v2_125:0xc.d = v3_100:0xc.d << 7
uint128_t v6_58 = v3_100 ^ v6_57
uint128_t v4_83 = v16_6 ^ v5_107
uint128_t v7_59 = v5_107 ^ v7_58
uint128_t v3_102 = v2_125 ^ v4_82 ^ v5_107
v5_107.d = v4_83.d u>> 0x1b
v5_107:4.d = v4_83:4.d u>> 0x1b
v5_107:8.d = v4_83:8.d u>> 0x1b
v5_107:0xc.d = v4_83:0xc.d u>> 0x1b
v4_83.d <<= 5
v4_83:4.d <<= 5
v4_83:8.d <<= 5
v4_83:0xc.d <<= 5
uint128_t v4_84 = vorrq_s8(v4_83, v5_107)
v5_107.d = v3_102.d u>> 0xa
v5_107:4.d = v3_102:4.d u>> 0xa
v5_107:8.d = v3_102:8.d u>> 0xa
v5_107:0xc.d = v3_102:0xc.d u>> 0xa
v3_102.d <<= 0x16
v3_102:4.d <<= 0x16
v3_102:8.d <<= 0x16
v3_102:0xc.d <<= 0x16
uint128_t v0_159 = v4_84 ^ v0_158
uint128_t v4_85 = v0_159 ^ v7_59
uint128_t v1_147 = vorrq_s8(v3_102, v5_107) ^ v1_146
uint128_t v6_59 = v1_147 ^ v6_58
uint128_t v0_160 = (v4_85 & v6_58) ^ v0_159
uint128_t v7_61 = v4_85 ^ v1_147
uint128_t v5_110 = vorrq_s8(v0_159, v7_59) ^ v6_59
uint128_t v4_86 = v4_85 ^ v6_59
uint128_t v1_149 = vorrq_s8(v0_160, v1_147) ^ v4_86
int128_t v4_88 = (v0_160 | not.o(v4_86)) ^ vorrq_s8(v5_110, v7_61)
uint128_t v0_161 = v4_88 ^ v7_61 ^ v0_160
uint128_t v7_62
v7_62.d = v1_149.d u>> 0x1d
v7_62:4.d = v1_149:4.d u>> 0x1d
v7_62:8.d = v1_149:8.d u>> 0x1d
v7_62:0xc.d = v1_149:0xc.d u>> 0x1d
v1_149.d <<= 3
v1_149:4.d <<= 3
v1_149:8.d <<= 3
v1_149:0xc.d <<= 3
uint128_t v1_150 = vorrq_s8(v1_149, v7_62)
v7_62.d = v0_161.d u>> 0x13
v7_62:4.d = v0_161:4.d u>> 0x13
v7_62:8.d = v0_161:8.d u>> 0x13
v7_62:0xc.d = v0_161:0xc.d u>> 0x13
v0_161.d <<= 0xd
v0_161:4.d <<= 0xd
v0_161:8.d <<= 0xd
v0_161:0xc.d <<= 0xd
uint128_t v0_162 = vorrq_s8(v0_161, v7_62)
int32_t temp0_94 = x8_2[0x65]
v2_125.d = temp0_94
v2_125:4.d = temp0_94
v2_125:8.d = temp0_94
v2_125:0xc.d = temp0_94
int128_t v4_90 = v4_88 ^ v1_150 ^ v0_162
v7_62.d = v0_162.d << 3
v7_62:4.d = v0_162:4.d << 3
v7_62:8.d = v0_162:8.d << 3
v7_62:0xc.d = v0_162:0xc.d << 3
uint128_t v5_112 = v1_150 ^ v5_110 ^ v7_62
v7_62.d = v4_90.d u>> 0x1f
v7_62:4.d = v4_90:4.d u>> 0x1f
v7_62:8.d = v4_90:8.d u>> 0x1f
v7_62:0xc.d = v4_90:0xc.d u>> 0x1f
v4_90.d <<= 1
v4_90:4.d <<= 1
v4_90:8.d <<= 1
v4_90:0xc.d <<= 1
int32_t temp0_95 = x8_2[0x67]
v3_102.d = temp0_95
v3_102:4.d = temp0_95
v3_102:8.d = temp0_95
v3_102:0xc.d = temp0_95
int128_t v6_60
v6_60.d = x8_2[0x64]
uint128_t v4_91 = vorrq_s8(v4_90, v7_62)
v7_62.d = v5_112.d u>> 0x19
v7_62:4.d = v5_112:4.d u>> 0x19
v7_62:8.d = v5_112:8.d u>> 0x19
v7_62:0xc.d = v5_112:0xc.d u>> 0x19
v5_112.d <<= 7
v5_112:4.d <<= 7
v5_112:8.d <<= 7
v5_112:0xc.d <<= 7
uint128_t v5_113 = vorrq_s8(v5_112, v7_62)
v7_62.d = x8_2[0x66]
uint128_t v0_163 = v4_91 ^ v0_162
uint128_t v2_126 = v4_91 ^ v2_125
v4_91.d <<= 7
v4_91:4.d <<= 7
v4_91:8.d <<= 7
v4_91:0xc.d <<= 7
uint128_t v0_164 = v0_163 ^ v5_113
uint128_t v3_103 = v5_113 ^ v3_102
uint128_t v1_152 = v4_91 ^ v1_150 ^ v5_113
v5_113.d = v0_164.d u>> 0x1b
v5_113:4.d = v0_164:4.d u>> 0x1b
v5_113:8.d = v0_164:8.d u>> 0x1b
v5_113:0xc.d = v0_164:0xc.d u>> 0x1b
v0_164.d <<= 5
v0_164:4.d <<= 5
v0_164:8.d <<= 5
v0_164:0xc.d <<= 5
uint128_t v6_62 = vdupq_laneq_s32(not.o(v6_60), 0)
uint128_t v0_165 = vorrq_s8(v0_164, v5_113)
v5_113.d = v1_152.d u>> 0xa
v5_113:4.d = v1_152:4.d u>> 0xa
v5_113:8.d = v1_152:8.d u>> 0xa
v5_113:0xc.d = v1_152:0xc.d u>> 0xa
v1_152.d <<= 0x16
v1_152:4.d <<= 0x16
v1_152:8.d <<= 0x16
v1_152:0xc.d <<= 0x16
uint128_t v0_166 = v6_62 ^ v0_165
uint128_t v5_114 = v0_166 & v2_126
uint128_t v1_155 = vdupq_laneq_s32(not.o(v7_62), 0) ^ vorrq_s8(v1_152, v5_113) ^ v5_114
uint128_t v5_115 = vorrq_s8(v5_114, v3_103)
uint128_t v2_127 = v5_115 ^ v2_126
uint128_t v5_116 = v5_115 ^ v0_166
uint128_t v3_104 = v1_155 ^ v3_103
uint128_t v0_167 = vorrq_s8(v2_127, v0_166)
uint128_t v2_128 = v3_104 ^ v2_127
v6_62.d = v3_104.d u>> 0x1d
v6_62:4.d = v3_104:4.d u>> 0x1d
v6_62:8.d = v3_104:8.d u>> 0x1d
v6_62:0xc.d = v3_104:0xc.d u>> 0x1d
v3_104.d <<= 3
v3_104:4.d <<= 3
v3_104:8.d <<= 3
v3_104:0xc.d <<= 3
uint128_t v1_157 = vorrq_s8(v5_116, v1_155) & v0_167
uint128_t v3_105 = vorrq_s8(v3_104, v6_62)
v6_62.d = v1_157.d u>> 0x13
v6_62:4.d = v1_157:4.d u>> 0x13
v6_62:8.d = v1_157:8.d u>> 0x13
v6_62:0xc.d = v1_157:0xc.d u>> 0x13
uint128_t v7_64
v7_64.d = v1_157.d << 0xd
v7_64:4.d = v1_157:4.d << 0xd
v7_64:8.d = v1_157:8.d << 0xd
v7_64:0xc.d = v1_157:0xc.d << 0xd
uint128_t v6_63 = vorrq_s8(v7_64, v6_62)
uint128_t v5_117 = v2_128 ^ v5_116
int32_t temp0_96 = x8_2[0x68]
v4_91.d = temp0_96
v4_91:4.d = temp0_96
v4_91:8.d = temp0_96
v4_91:0xc.d = temp0_96
uint128_t v0_170 = v0_167 ^ v3_105 ^ v6_63 ^ (v1_157 & v5_117)
uint128_t v1_158
v1_158.d = v6_63.d << 3
v1_158:4.d = v6_63:4.d << 3
v1_158:8.d = v6_63:8.d << 3
v1_158:0xc.d = v6_63:0xc.d << 3
int32_t temp0_97 = x8_2[0x69]
v7_64.d = temp0_97
v7_64:4.d = temp0_97
v7_64:8.d = temp0_97
v7_64:0xc.d = temp0_97
uint128_t v1_159 = v5_117 ^ v3_105 ^ (v1_157 & v2_128) ^ v1_158
uint128_t v2_130
v2_130.d = v0_170.d u>> 0x1f
v2_130:4.d = v0_170:4.d u>> 0x1f
v2_130:8.d = v0_170:8.d u>> 0x1f
v2_130:0xc.d = v0_170:0xc.d u>> 0x1f
v0_170.d <<= 1
v0_170:4.d <<= 1
v0_170:8.d <<= 1
v0_170:0xc.d <<= 1
int32_t temp0_98 = x8_2[0x6a]
uint128_t v5_118
v5_118.d = temp0_98
v5_118:4.d = temp0_98
v5_118:8.d = temp0_98
v5_118:0xc.d = temp0_98
uint128_t v0_171 = vorrq_s8(v0_170, v2_130)
v2_130.d = v1_159.d u>> 0x19
v2_130:4.d = v1_159:4.d u>> 0x19
v2_130:8.d = v1_159:8.d u>> 0x19
v2_130:0xc.d = v1_159:0xc.d u>> 0x19
v1_159.d <<= 7
v1_159:4.d <<= 7
v1_159:8.d <<= 7
v1_159:0xc.d <<= 7
uint128_t v1_160 = vorrq_s8(v1_159, v2_130)
int32_t temp0_99 = x8_2[0x6b]
v2_130.d = temp0_99
v2_130:4.d = temp0_99
v2_130:8.d = temp0_99
v2_130:0xc.d = temp0_99
uint128_t v7_65 = v0_171 ^ v7_64
uint128_t v2_131 = v1_160 ^ v2_130
uint128_t v1_161 = v0_171 ^ v6_63 ^ v1_160
v0_171.d <<= 7
v0_171:4.d <<= 7
v0_171:8.d <<= 7
v0_171:0xc.d <<= 7
uint128_t v0_172 = v1_160 ^ v3_105 ^ v0_171
uint128_t v3_106
v3_106.d = v1_161.d u>> 0x1b
v3_106:4.d = v1_161:4.d u>> 0x1b
v3_106:8.d = v1_161:8.d u>> 0x1b
v3_106:0xc.d = v1_161:0xc.d u>> 0x1b
v1_161.d <<= 5
v1_161:4.d <<= 5
v1_161:8.d <<= 5
v1_161:0xc.d <<= 5
uint128_t v1_162 = vorrq_s8(v1_161, v3_106)
v3_106.d = v0_172.d u>> 0xa
v3_106:4.d = v0_172:4.d u>> 0xa
v3_106:8.d = v0_172:8.d u>> 0xa
v3_106:0xc.d = v0_172:0xc.d u>> 0xa
v0_172.d <<= 0x16
v0_172:4.d <<= 0x16
v0_172:8.d <<= 0x16
v0_172:0xc.d <<= 0x16
uint128_t v1_163 = v1_162 ^ v4_91
uint128_t v0_174 = vorrq_s8(v0_172, v3_106) ^ v5_118
uint128_t v5_120 = (v0_174 & v1_163) ^ v2_131
uint128_t v0_176 = v0_174 ^ v7_65 ^ v5_120
uint128_t v2_133 = vorrq_s8(v1_163, v2_131) ^ v7_65
uint128_t v1_164 = v0_176 ^ v1_163
v7_65.d = v0_176.d u>> 0x13
v7_65:4.d = v0_176:4.d u>> 0x13
v7_65:8.d = v0_176:8.d u>> 0x13
v7_65:0xc.d = v0_176:0xc.d u>> 0x13
v0_176.d <<= 0xd
v0_176:4.d <<= 0xd
v0_176:8.d <<= 0xd
v0_176:0xc.d <<= 0xd
uint128_t v0_177 = vorrq_s8(v0_176, v7_65)
uint128_t v7_67 = v1_164 ^ (v5_120 & v2_133)
uint128_t v1_166 = vorrq_s8(v1_164, v2_133) ^ v5_120
v5_120.d = v0_177.d << 3
v5_120:4.d = v0_177:4.d << 3
v5_120:8.d = v0_177:8.d << 3
v5_120:0xc.d = v0_177:0xc.d << 3
uint128_t v2_135 = v7_67 ^ v2_133 ^ v1_166
uint128_t v5_121 = v5_120 ^ v7_67
v7_67.d = v2_135.d u>> 0x1d
v7_67:4.d = v2_135:4.d u>> 0x1d
v7_67:8.d = v2_135:8.d u>> 0x1d
v7_67:0xc.d = v2_135:0xc.d u>> 0x1d
v2_135.d <<= 3
v2_135:4.d <<= 3
v2_135:8.d <<= 3
v2_135:0xc.d <<= 3
int32_t temp0_100 = x8_2[0x6c]
uint128_t v6_64
v6_64.d = temp0_100
v6_64:4.d = temp0_100
v6_64:8.d = temp0_100
v6_64:0xc.d = temp0_100
uint128_t v2_136 = vorrq_s8(v2_135, v7_67)
int32_t temp0_101 = x8_2[0x6d]
v3_106.d = temp0_101
v3_106:4.d = temp0_101
v3_106:8.d = temp0_101
v3_106:0xc.d = temp0_101
uint128_t v1_168 = v1_166 ^ v0_177 ^ v2_136
uint128_t v5_123 = not.o(v5_121 ^ v2_136)
v7_67.d = v1_168.d u>> 0x1f
v7_67:4.d = v1_168:4.d u>> 0x1f
v7_67:8.d = v1_168:8.d u>> 0x1f
v7_67:0xc.d = v1_168:0xc.d u>> 0x1f
v1_168.d <<= 1
v1_168:4.d <<= 1
v1_168:8.d <<= 1
v1_168:0xc.d <<= 1
uint128_t v1_169 = vorrq_s8(v1_168, v7_67)
v7_67.d = v5_123.d u>> 0x19
v7_67:4.d = v5_123:4.d u>> 0x19
v7_67:8.d = v5_123:8.d u>> 0x19
v7_67:0xc.d = v5_123:0xc.d u>> 0x19
v5_123.d <<= 7
v5_123:4.d <<= 7
v5_123:8.d <<= 7
v5_123:0xc.d <<= 7
int32_t temp0_102 = x8_2[0x6e]
v4_91.d = temp0_102
v4_91:4.d = temp0_102
v4_91:8.d = temp0_102
v4_91:0xc.d = temp0_102
uint128_t v5_124 = vorrq_s8(v5_123, v7_67)
int32_t temp0_103 = x8_2[0x6f]
v7_67.d = temp0_103
v7_67:4.d = temp0_103
v7_67:8.d = temp0_103
v7_67:0xc.d = temp0_103
uint128_t v0_179 = v1_169 ^ v0_177 ^ v5_124
uint128_t v3_107 = v1_169 ^ v3_106
v1_169.d <<= 7
v1_169:4.d <<= 7
v1_169:8.d <<= 7
v1_169:0xc.d <<= 7
uint128_t v1_170 = v5_124 ^ v2_136 ^ v1_169
uint128_t v2_137
v2_137.d = v0_179.d u>> 0x1b
v2_137:4.d = v0_179:4.d u>> 0x1b
v2_137:8.d = v0_179:8.d u>> 0x1b
v2_137:0xc.d = v0_179:0xc.d u>> 0x1b
v0_179.d <<= 5
v0_179:4.d <<= 5
v0_179:8.d <<= 5
v0_179:0xc.d <<= 5
uint128_t v0_180 = vorrq_s8(v0_179, v2_137)
v2_137.d = v1_170.d u>> 0xa
v2_137:4.d = v1_170:4.d u>> 0xa
v2_137:8.d = v1_170:8.d u>> 0xa
v2_137:0xc.d = v1_170:0xc.d u>> 0xa
v1_170.d <<= 0x16
v1_170:4.d <<= 0x16
v1_170:8.d <<= 0x16
v1_170:0xc.d <<= 0x16
uint128_t v5_125 = v5_124 ^ v7_67
uint128_t v0_181 = v0_180 ^ v6_64
uint128_t v1_172 = vorrq_s8(v1_170, v2_137) ^ v4_91
uint128_t v2_138 = v5_125 ^ v3_107
uint128_t v4_92 = vorrq_s8(v0_181, v5_125)
uint128_t v3_108 = v0_181 & v3_107
uint128_t v0_182 = v1_172 ^ v0_181
uint128_t v1_173 = v1_172 ^ v2_138
uint128_t v2_140 = vorrq_s8(v3_108, v0_182) ^ (v4_92 & v2_138)
uint128_t v4_93 = v3_108 ^ v4_92
uint128_t v0_184 = (v4_93 & v0_182) ^ v1_173
uint128_t v1_174 = vorrq_s8(v2_140 ^ v3_108, v4_93) ^ v1_173
uint128_t v5_126
v5_126.d = v2_140.d u>> 0x1d
v5_126:4.d = v2_140:4.d u>> 0x1d
v5_126:8.d = v2_140:8.d u>> 0x1d
v5_126:0xc.d = v2_140:0xc.d u>> 0x1d
v6_64.d = v2_140.d << 3
v6_64:4.d = v2_140:4.d << 3
v6_64:8.d = v2_140:8.d << 3
v6_64:0xc.d = v2_140:0xc.d << 3
uint128_t v2_142 = (v1_174 & not.o(v2_140)) ^ v4_93
uint128_t v5_127 = vorrq_s8(v6_64, v5_126)
v4_93.d = v2_142.d u>> 0x13
v4_93:4.d = v2_142:4.d u>> 0x13
v4_93:8.d = v2_142:8.d u>> 0x13
v4_93:0xc.d = v2_142:0xc.d u>> 0x13
v2_142.d <<= 0xd
v2_142:4.d <<= 0xd
v2_142:8.d <<= 0xd
v2_142:0xc.d <<= 0xd
uint128_t v2_143 = vorrq_s8(v2_142, v4_93)
int32_t temp0_104 = x8_2[0x70]
v7_67.d = temp0_104
v7_67:4.d = temp0_104
v7_67:8.d = temp0_104
v7_67:0xc.d = temp0_104
uint128_t v1_176 = v1_174 ^ v5_127 ^ v2_143
v4_93.d = v2_143.d << 3
v4_93:4.d = v2_143:4.d << 3
v4_93:8.d = v2_143:8.d << 3
v4_93:0xc.d = v2_143:0xc.d << 3
int32_t temp0_105 = x8_2[0x71]
v6_64.d = temp0_105
v6_64:4.d = temp0_105
v6_64:8.d = temp0_105
v6_64:0xc.d = temp0_105
uint128_t v0_186 = v0_184 ^ v5_127 ^ v4_93
v4_93.d = v1_176.d u>> 0x1f
v4_93:4.d = v1_176:4.d u>> 0x1f
v4_93:8.d = v1_176:8.d u>> 0x1f
v4_93:0xc.d = v1_176:0xc.d u>> 0x1f
v1_176.d <<= 1
v1_176:4.d <<= 1
v1_176:8.d <<= 1
v1_176:0xc.d <<= 1
int32_t temp0_106 = x8_2[0x72]
uint128_t v3_110
v3_110.d = temp0_106
v3_110:4.d = temp0_106
v3_110:8.d = temp0_106
v3_110:0xc.d = temp0_106
uint128_t v1_177 = vorrq_s8(v1_176, v4_93)
v4_93.d = v0_186.d u>> 0x19
v4_93:4.d = v0_186:4.d u>> 0x19
v4_93:8.d = v0_186:8.d u>> 0x19
v4_93:0xc.d = v0_186:0xc.d u>> 0x19
v0_186.d <<= 7
v0_186:4.d <<= 7
v0_186:8.d <<= 7
v0_186:0xc.d <<= 7
uint128_t v0_187 = vorrq_s8(v0_186, v4_93)
int32_t temp0_107 = x8_2[0x73]
v4_93.d = temp0_107
v4_93:4.d = temp0_107
v4_93:8.d = temp0_107
v4_93:0xc.d = temp0_107
uint128_t v2_145 = v1_177 ^ v2_143 ^ v0_187
uint128_t v6_65 = v1_177 ^ v6_64
v1_177.d <<= 7
v1_177:4.d <<= 7
v1_177:8.d <<= 7
v1_177:0xc.d <<= 7
uint128_t v0_188 = v0_187 ^ v4_93
uint128_t v1_178 = v0_187 ^ v5_127 ^ v1_177
uint128_t v5_128
v5_128.d = v2_145.d u>> 0x1b
v5_128:4.d = v2_145:4.d u>> 0x1b
v5_128:8.d = v2_145:8.d u>> 0x1b
v5_128:0xc.d = v2_145:0xc.d u>> 0x1b
v2_145.d <<= 5
v2_145:4.d <<= 5
v2_145:8.d <<= 5
v2_145:0xc.d <<= 5
uint128_t v5_129 = not.o(v0_188)
uint128_t v5_130 = v7_67 ^ v5_129
v7_67.d = v1_178.d u>> 0xa
v7_67:4.d = v1_178:4.d u>> 0xa
v7_67:8.d = v1_178:8.d u>> 0xa
v7_67:0xc.d = v1_178:0xc.d u>> 0xa
v1_178.d <<= 0x16
v1_178:4.d <<= 0x16
v1_178:8.d <<= 0x16
v1_178:0xc.d <<= 0x16
uint128_t v0_189 = v0_188 ^ v6_65
uint128_t v2_147 = v5_130 ^ vorrq_s8(v2_145, v5_128)
uint128_t v1_180 = v3_110 ^ v5_129 ^ vorrq_s8(v1_178, v7_67)
uint128_t v0_190 = v2_147 ^ v0_189
uint128_t v3_113 = v1_180 ^ (v2_147 & v0_189)
uint128_t v1_181 = v1_180 & v0_190
uint128_t v5_131 = v1_181 ^ not.o(v6_65)
uint128_t v7_69 = v3_113 & not.o(v6_65)
uint128_t v0_191 = vorrq_s8(v3_113, v0_190)
uint128_t v1_182 = v1_181 ^ v6_65
v6_65.d = v3_113.d u>> 0x13
v6_65:4.d = v3_113:4.d u>> 0x13
v6_65:8.d = v3_113:8.d u>> 0x13
v6_65:0xc.d = v3_113:0xc.d u>> 0x13
v3_113.d <<= 0xd
v3_113:4.d <<= 0xd
v3_113:8.d <<= 0xd
v3_113:0xc.d <<= 0xd
uint128_t v3_114 = vorrq_s8(v3_113, v6_65)
uint128_t v6_66 = v7_69 ^ v2_147
uint128_t v1_183 = v1_182 ^ vorrq_s8(v7_69, v2_147)
uint128_t v0_194 = v7_69 ^ v0_191 ^ v3_114 ^ (v6_66 & v5_131)
uint128_t v5_132
v5_132.d = v3_114.d << 3
v5_132:4.d = v3_114:4.d << 3
v5_132:8.d = v3_114:8.d << 3
v5_132:0xc.d = v3_114:0xc.d << 3
uint128_t v5_133 = v6_66 ^ v5_132
v6_66.d = v1_183.d u>> 0x1d
v6_66:4.d = v1_183:4.d u>> 0x1d
v6_66:8.d = v1_183:8.d u>> 0x1d
v6_66:0xc.d = v1_183:0xc.d u>> 0x1d
v1_183.d <<= 3
v1_183:4.d <<= 3
v1_183:8.d <<= 3
v1_183:0xc.d <<= 3
uint128_t v1_184 = vorrq_s8(v1_183, v6_66)
int32_t temp0_108 = x8_2[0x74]
v4_93.d = temp0_108
v4_93:4.d = temp0_108
v4_93:8.d = temp0_108
v4_93:0xc.d = temp0_108
uint128_t v0_195 = v0_194 ^ v1_184
int32_t temp0_109 = x8_2[0x75]
v7_69.d = temp0_109
v7_69:4.d = temp0_109
v7_69:8.d = temp0_109
v7_69:0xc.d = temp0_109
uint128_t v5_134 = v5_133 ^ v1_184
v6_66.d = v0_195.d u>> 0x1f
v6_66:4.d = v0_195:4.d u>> 0x1f
v6_66:8.d = v0_195:8.d u>> 0x1f
v6_66:0xc.d = v0_195:0xc.d u>> 0x1f
v0_195.d <<= 1
v0_195:4.d <<= 1
v0_195:8.d <<= 1
v0_195:0xc.d <<= 1
int32_t temp0_110 = x8_2[0x76]
uint128_t v2_148
v2_148.d = temp0_110
v2_148:4.d = temp0_110
v2_148:8.d = temp0_110
v2_148:0xc.d = temp0_110
uint128_t v0_196 = vorrq_s8(v0_195, v6_66)
v6_66.d = v5_134.d u>> 0x19
v6_66:4.d = v5_134:4.d u>> 0x19
v6_66:8.d = v5_134:8.d u>> 0x19
v6_66:0xc.d = v5_134:0xc.d u>> 0x19
v5_134.d <<= 7
v5_134:4.d <<= 7
v5_134:8.d <<= 7
v5_134:0xc.d <<= 7
uint128_t v5_135 = vorrq_s8(v5_134, v6_66)
int32_t temp0_111 = x8_2[0x77]
v6_66.d = temp0_111
v6_66:4.d = temp0_111
v6_66:8.d = temp0_111
v6_66:0xc.d = temp0_111
uint128_t v3_115 = v0_196 ^ v3_114
uint128_t v7_70 = v0_196 ^ v7_69
uint128_t v6_67 = v5_135 ^ v6_66
v0_196.d <<= 7
v0_196:4.d <<= 7
v0_196:8.d <<= 7
v0_196:0xc.d <<= 7
uint128_t v3_116 = v3_115 ^ v5_135
uint128_t v0_197 = v5_135 ^ v1_184 ^ v0_196
uint128_t v1_187 = v2_148 ^ not.o(v6_67)
v2_148.d = v3_116.d u>> 0x1b
v2_148:4.d = v3_116:4.d u>> 0x1b
v2_148:8.d = v3_116:8.d u>> 0x1b
v2_148:0xc.d = v3_116:0xc.d u>> 0x1b
v3_116.d <<= 5
v3_116:4.d <<= 5
v3_116:8.d <<= 5
v3_116:0xc.d <<= 5
uint128_t v2_149 = vorrq_s8(v3_116, v2_148)
v3_116.d = v0_197.d u>> 0xa
v3_116:4.d = v0_197:4.d u>> 0xa
v3_116:8.d = v0_197:8.d u>> 0xa
v3_116:0xc.d = v0_197:0xc.d u>> 0xa
v0_197.d <<= 0x16
v0_197:4.d <<= 0x16
v0_197:8.d <<= 0x16
v0_197:0xc.d <<= 0x16
uint128_t v2_150 = v7_70 ^ v4_93 ^ v2_149
uint128_t v4_95 = v6_67 ^ v7_70
uint128_t v0_199 = v1_187 ^ vorrq_s8(v0_197, v3_116)
uint128_t v4_96 = vorrq_s8(v0_199, v4_95)
uint128_t v0_200 = (v2_150 & v4_95) ^ v0_199
uint128_t v6_68 = v0_200 & not.o(v6_67)
uint128_t v1_190 = v4_96 ^ v7_70 ^ v0_200
v7_70.d = v0_200.d u>> 0x13
v7_70:4.d = v0_200:4.d u>> 0x13
v7_70:8.d = v0_200:8.d u>> 0x13
v7_70:0xc.d = v0_200:0xc.d u>> 0x13
v0_200.d <<= 0xd
v0_200:4.d <<= 0xd
v0_200:8.d <<= 0xd
v0_200:0xc.d <<= 0xd
uint128_t v6_69 = v6_68 ^ v2_150
uint128_t v0_201 = vorrq_s8(v0_200, v7_70)
uint128_t v2_152 = (v6_69 & v2_150) ^ not.o(v1_190)
uint128_t v7_71
v7_71.d = v0_201.d << 3
v7_71:4.d = v0_201:4.d << 3
v7_71:8.d = v0_201:8.d << 3
v7_71:0xc.d = v0_201:0xc.d << 3
uint128_t v4_98
v4_98.d = v2_152.d u>> 0x1d
v4_98:4.d = v2_152:4.d u>> 0x1d
v4_98:8.d = v2_152:8.d u>> 0x1d
v4_98:0xc.d = v2_152:0xc.d u>> 0x1d
v2_152.d <<= 3
v2_152:4.d <<= 3
v2_152:8.d <<= 3
v2_152:0xc.d <<= 3
int32_t temp0_112 = x8_2[0x78]
v5_135.d = temp0_112
v5_135:4.d = temp0_112
v5_135:8.d = temp0_112
v5_135:0xc.d = temp0_112
uint128_t v2_153 = vorrq_s8(v2_152, v4_98)
int32_t temp0_113 = x8_2[0x79]
v3_116.d = temp0_113
v3_116:4.d = temp0_113
v3_116:8.d = temp0_113
v3_116:0xc.d = temp0_113
uint128_t v4_99 = v6_69 ^ v0_201 ^ v2_153
uint128_t v1_194 = not.o(v4_96 ^ v2_150 ^ v7_71 ^ (v6_69 | not.o(v1_190)) ^ v2_153)
uint128_t v6_70
v6_70.d = v4_99.d u>> 0x1f
v6_70:4.d = v4_99:4.d u>> 0x1f
v6_70:8.d = v4_99:8.d u>> 0x1f
v6_70:0xc.d = v4_99:0xc.d u>> 0x1f
v4_99.d <<= 1
v4_99:4.d <<= 1
v4_99:8.d <<= 1
v4_99:0xc.d <<= 1
uint128_t v4_100 = vorrq_s8(v4_99, v6_70)
v6_70.d = v1_194.d u>> 0x19
v6_70:4.d = v1_194:4.d u>> 0x19
v6_70:8.d = v1_194:8.d u>> 0x19
v6_70:0xc.d = v1_194:0xc.d u>> 0x19
v1_194.d <<= 7
v1_194:4.d <<= 7
v1_194:8.d <<= 7
v1_194:0xc.d <<= 7
int32_t temp0_114 = x8_2[0x7a]
v7_71.d = temp0_114
v7_71:4.d = temp0_114
v7_71:8.d = temp0_114
v7_71:0xc.d = temp0_114
uint128_t v1_195 = vorrq_s8(v1_194, v6_70)
int32_t temp0_115 = x8_2[0x7b]
v6_70.d = temp0_115
v6_70:4.d = temp0_115
v6_70:8.d = temp0_115
v6_70:0xc.d = temp0_115
uint128_t v0_203 = v4_100 ^ v0_201 ^ v1_195
uint128_t v3_117 = v4_100 ^ v3_116
v4_100.d <<= 7
v4_100:4.d <<= 7
v4_100:8.d <<= 7
v4_100:0xc.d <<= 7
uint128_t v2_155 = v1_195 ^ v2_153 ^ v4_100
v4_100.d = v0_203.d u>> 0x1b
v4_100:4.d = v0_203:4.d u>> 0x1b
v4_100:8.d = v0_203:8.d u>> 0x1b
v4_100:0xc.d = v0_203:0xc.d u>> 0x1b
v0_203.d <<= 5
v0_203:4.d <<= 5
v0_203:8.d <<= 5
v0_203:0xc.d <<= 5
uint128_t v0_204 = vorrq_s8(v0_203, v4_100)
v4_100.d = v2_155.d u>> 0xa
v4_100:4.d = v2_155:4.d u>> 0xa
v4_100:8.d = v2_155:8.d u>> 0xa
v4_100:0xc.d = v2_155:0xc.d u>> 0xa
v2_155.d <<= 0x16
v2_155:4.d <<= 0x16
v2_155:8.d <<= 0x16
v2_155:0xc.d <<= 0x16
uint128_t v1_196 = v1_195 ^ v6_70
uint128_t v0_205 = v0_204 ^ v5_135
uint128_t v2_157 = vorrq_s8(v2_155, v4_100) ^ v7_71
uint128_t v5_136 = v0_205 & v1_196
uint128_t v7_73 = v5_136 ^ not.o(v2_157)
uint128_t v0_206 = v0_205 ^ v1_196
uint128_t v3_118 = v3_117 ^ v7_73
uint128_t v0_207 = vorrq_s8(v3_118, v0_206)
int128_t v2_160 = (v1_196 | not.o(v2_157)) ^ v0_206 ^ v3_118
int128_t v1_198 = vorrq_s8(v0_207, v7_73) ^ v2_160
uint128_t v0_209 = v7_73 ^ v1_196 ^ v0_207 ^ v1_198
uint128_t v7_74
v7_74.d = v1_198.d u>> 0x13
v7_74:4.d = v1_198:4.d u>> 0x13
v7_74:8.d = v1_198:8.d u>> 0x13
v7_74:0xc.d = v1_198:0xc.d u>> 0x13
v1_198.d <<= 0xd
v1_198:4.d <<= 0xd
v1_198:8.d <<= 0xd
v1_198:0xc.d <<= 0xd
int128_t v2_161 = v0_209 & v2_160
uint128_t v1_199 = vorrq_s8(v1_198, v7_74)
v7_74.d = v0_209.d u>> 0x1d
v7_74:4.d = v0_209:4.d u>> 0x1d
v7_74:8.d = v0_209:8.d u>> 0x1d
v7_74:0xc.d = v0_209:0xc.d u>> 0x1d
v0_209.d <<= 3
v0_209:4.d <<= 3
v0_209:8.d <<= 3
v0_209:0xc.d <<= 3
uint128_t v0_210 = vorrq_s8(v0_209, v7_74)
v7_74.d = v1_199.d << 3
v7_74:4.d = v1_199:4.d << 3
v7_74:8.d = v1_199:8.d << 3
v7_74:0xc.d = v1_199:0xc.d << 3
int32_t temp0_116 = x8_2[0x7c]
v6_70.d = temp0_116
v6_70:4.d = temp0_116
v6_70:8.d = temp0_116
v6_70:0xc.d = temp0_116
uint128_t v3_120 = v1_199 ^ v3_118 ^ v0_210
int32_t temp0_117 = x8_2[0x7d]
v4_100.d = temp0_117
v4_100:4.d = temp0_117
v4_100:8.d = temp0_117
v4_100:0xc.d = temp0_117
int128_t v2_162 = v5_136 ^ v2_157 ^ v7_74 ^ v0_210 ^ v2_161
uint128_t v5_139
v5_139.d = v3_120.d u>> 0x1f
v5_139:4.d = v3_120:4.d u>> 0x1f
v5_139:8.d = v3_120:8.d u>> 0x1f
v5_139:0xc.d = v3_120:0xc.d u>> 0x1f
v3_120.d <<= 1
v3_120:4.d <<= 1
v3_120:8.d <<= 1
v3_120:0xc.d <<= 1
int32_t temp0_118 = x8_2[0x7e]
v7_74.d = temp0_118
v7_74:4.d = temp0_118
v7_74:8.d = temp0_118
v7_74:0xc.d = temp0_118
uint128_t v3_121 = vorrq_s8(v3_120, v5_139)
v5_139.d = v2_162.d u>> 0x19
v5_139:4.d = v2_162:4.d u>> 0x19
v5_139:8.d = v2_162:8.d u>> 0x19
v5_139:0xc.d = v2_162:0xc.d u>> 0x19
v2_162.d <<= 7
v2_162:4.d <<= 7
v2_162:8.d <<= 7
v2_162:0xc.d <<= 7
uint128_t v2_163 = vorrq_s8(v2_162, v5_139)
int32_t temp0_119 = x8_2[0x7f]
v5_139.d = temp0_119
v5_139:4.d = temp0_119
v5_139:8.d = temp0_119
v5_139:0xc.d = temp0_119
uint128_t v1_201 = v3_121 ^ v1_199 ^ v2_163
uint128_t v4_101 = v3_121 ^ v4_100
v3_121.d <<= 7
v3_121:4.d <<= 7
v3_121:8.d <<= 7
v3_121:0xc.d <<= 7
uint128_t v0_212 = v2_163 ^ v0_210 ^ v3_121
v3_121.d = v1_201.d u>> 0x1b
v3_121:4.d = v1_201:4.d u>> 0x1b
v3_121:8.d = v1_201:8.d u>> 0x1b
v3_121:0xc.d = v1_201:0xc.d u>> 0x1b
v1_201.d <<= 5
v1_201:4.d <<= 5
v1_201:8.d <<= 5
v1_201:0xc.d <<= 5
uint128_t v2_164 = v2_163 ^ v5_139
int32_t temp0_120 = x8_2[0x80]
v5_139.d = temp0_120
v5_139:4.d = temp0_120
v5_139:8.d = temp0_120
v5_139:0xc.d = temp0_120
uint128_t v1_202 = vorrq_s8(v1_201, v3_121)
v3_121.d = v0_212.d u>> 0xa
v3_121:4.d = v0_212:4.d u>> 0xa
v3_121:8.d = v0_212:8.d u>> 0xa
v3_121:0xc.d = v0_212:0xc.d u>> 0xa
v0_212.d <<= 0x16
v0_212:4.d <<= 0x16
v0_212:8.d <<= 0x16
v0_212:0xc.d <<= 0x16
uint128_t v0_213 = vorrq_s8(v0_212, v3_121)
int32_t temp0_121 = x8_2[0x81]
v3_121.d = temp0_121
v3_121:4.d = temp0_121
v3_121:8.d = temp0_121
v3_121:0xc.d = temp0_121
uint128_t v0_214 = v0_213 ^ v7_74
uint128_t v1_203 = v1_202 ^ v6_70
uint128_t v6_72 = vorrq_s8(v0_214, v4_101) ^ v2_164
uint128_t v2_165 = vorrq_s8(v0_214 ^ v4_101, v2_164)
uint128_t v0_215 = v6_72 ^ v0_214
uint128_t v7_76 = v6_72 ^ v4_101
uint128_t v4_102 = vorrq_s8(v6_72, v4_101)
uint128_t v3_122 = v6_72 ^ v3_121
int32_t temp0_122 = x8_2[0x82]
v6_72.d = temp0_122
v6_72:4.d = temp0_122
v6_72:8.d = temp0_122
v6_72:0xc.d = temp0_122
uint128_t v2_167 = v3_122 ^ (v2_165 & v1_203)
uint128_t v3_123 = vorrq_s8(v7_76, v1_203)
uint128_t v1_204 = v7_76 ^ v1_203
uint128_t v5_140 = v7_76 ^ v5_139
uint128_t v6_73 = v7_76 ^ v6_72
int32_t temp0_123 = x8_2[0x83]
v7_76.d = temp0_123
v7_76:4.d = temp0_123
v7_76:8.d = temp0_123
v7_76:0xc.d = temp0_123
uint128_t v1_205 = v1_204 ^ v4_102
uint128_t v3_124 = v3_123 ^ v0_215
uint128_t v1_206 = v3_124 ^ v7_76
uint128_t v3_125 = v6_73 ^ (v1_205 & v3_124)
uint128_t v0_218 = v5_140 ^ (v3_124 | not.o(v0_215 ^ v1_205))
uint128_t v4_104 = vzip1q_s32(v0_218, v3_125)
uint128_t v6_74 = vzip2q_s32(v0_218, v3_125)
uint128_t v5_141 = vzip1q_s32(v2_167, v1_206)
uint128_t v7_77 = vzip2q_s32(v2_167, v1_206)
int64_t v0_219 = vextq_s8(v4_104, v4_104, 8)
int64_t v2_168 = vextq_s8(v6_74, v6_74, 8)
int32_t* entry_x2
*entry_x2 = v4_104.d
entry_x2[1] = v5_141.d
entry_x2[2] = v4_104:4.d
entry_x2[3] = v5_141:4.d
int64_t v1_207 = vextq_s8(v5_141, v5_141, 8)
int64_t v3_126 = vextq_s8(v7_77, v7_77, 8)
entry_x2[4] = v0_219.d
entry_x2[5] = v1_207.d
entry_x2[6] = v0_219:4.d
entry_x2[7] = v1_207:4.d
entry_x2[8] = v6_74.d
entry_x2[9] = v7_77.d
entry_x2[0xa] = v6_74:4.d
entry_x2[0xb] = v7_77:4.d
entry_x2[0xc] = v2_168.d
entry_x2[0xd] = v3_126.d
entry_x2[0xe] = v2_168:4.d
entry_x2[0xf] = v3_126:4.d
