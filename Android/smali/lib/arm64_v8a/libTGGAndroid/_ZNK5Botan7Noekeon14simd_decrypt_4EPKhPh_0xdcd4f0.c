// 函数: _ZNK5Botan7Noekeon14simd_decrypt_4EPKhPh
// 地址: 0xdcd4f0
// 来自: E:\torrent\Cursor\Dominion_1.0.3315\split_config.arm64_v8a\lib\arm64-v8a\libTGGAndroid.so

int32_t* x8 = *(arg1 + 0x20)
int32_t temp0 = *x8
int128_t v2
v2.d = temp0
v2:4.d = temp0
v2:8.d = temp0
v2:0xc.d = temp0
uint128_t v5 = *(arg2 + 0x10)
uint128_t v6 = *(arg2 + 0x20)
uint128_t v7 = *(arg2 + 0x30)
int32_t temp0_1 = x8[2]
int128_t v1
v1.d = temp0_1
v1:4.d = temp0_1
v1:8.d = temp0_1
v1:0xc.d = temp0_1
int32_t temp0_2 = x8[3]
int128_t v0
v0.d = temp0_2
v0:4.d = temp0_2
v0:8.d = temp0_2
v0:0xc.d = temp0_2
int32_t temp0_3 = *x8
int128_t v3
v3.d = temp0_3
v3:4.d = temp0_3
v3:8.d = temp0_3
v3:0xc.d = temp0_3
uint128_t v4_1 = vrev32q_s8(*arg2)
uint128_t v5_1 = vrev32q_s8(v5)
uint128_t v6_1 = vrev32q_s8(v6)
uint128_t v7_1 = vrev32q_s8(v7)
uint128_t v16 = vzip1q_s32(v4_1, v6_1)
uint128_t v6_2 = vzip2q_s32(v4_1, v6_1)
uint128_t v4_2 = vzip1q_s32(v5_1, v7_1)
uint128_t v17 = vzip2q_s32(v5_1, v7_1)
uint128_t v5_2 = vzip1q_s32(v16, v4_2)
uint128_t v7_2 = vzip2q_s32(v16, v4_2)
uint128_t v4_3 = vzip1q_s32(v6_2, v17)
uint128_t v6_3 = vzip2q_s32(v6_2, v17)
int64_t i_1 = 0x10
uint128_t v19
int64_t i

do
    uint128_t v16_1 = v5_2 ^ v4_3
    int128_t v7_3 = v7_2 ^ v3
    int128_t v6_4 = v6_3 ^ v0
    v17.d = v16_1.d u>> 0x18
    v17:4.d = v16_1:4.d u>> 0x18
    v17:8.d = v16_1:8.d u>> 0x18
    v17:0xc.d = v16_1:0xc.d u>> 0x18
    uint128_t v18
    v18.d = v16_1.d << 8
    v18:4.d = v16_1:4.d << 8
    v18:8.d = v16_1:8.d << 8
    v18:0xc.d = v16_1:0xc.d << 8
    v19.d = v16_1.d u>> 8
    v19:4.d = v16_1:4.d u>> 8
    v19:8.d = v16_1:8.d u>> 8
    v19:0xc.d = v16_1:0xc.d u>> 8
    uint128_t v20
    v20.d = v16_1.d << 0x18
    v20:4.d = v16_1:4.d << 0x18
    v20:8.d = v16_1:8.d << 0x18
    v20:0xc.d = v16_1:0xc.d << 0x18
    int128_t v21_1 = v6_4 ^ v7_3
    uint128_t v17_1 = vorrq_s8(v18, v17)
    uint128_t v18_1 = vorrq_s8(v20, v19)
    v19.d = v21_1.d u>> 0x18
    v19:4.d = v21_1:4.d u>> 0x18
    v19:8.d = v21_1:8.d u>> 0x18
    v19:0xc.d = v21_1:0xc.d u>> 0x18
    v20.d = v21_1.d << 8
    v20:4.d = v21_1:4.d << 8
    v20:8.d = v21_1:8.d << 8
    v20:0xc.d = v21_1:0xc.d << 8
    uint128_t v16_2 = v17_1 ^ v16_1
    v17_1.d = v21_1.d u>> 8
    v17_1:4.d = v21_1:4.d u>> 8
    v17_1:8.d = v21_1:8.d u>> 8
    v17_1:0xc.d = v21_1:0xc.d u>> 8
    v19 = vorrq_s8(v20, v19)
    v20.d = v21_1.d << 0x18
    v20:4.d = v21_1:4.d << 0x18
    v20:8.d = v21_1:8.d << 0x18
    v20:0xc.d = v21_1:0xc.d << 0x18
    uint128_t v16_3 = v16_2 ^ v18_1
    uint128_t v7_4 = v7_3 ^ v16_3
    uint128_t v6_5 = v6_4 ^ v16_3
    uint128_t v16_4 = v19 ^ v21_1 ^ vorrq_s8(v20, v17_1)
    int128_t v5_4 = v5_2 ^ v2 ^ v16_4
    uint128_t v4_5 = v4_3 ^ v1 ^ v16_4
    v16_4.d = v7_4.d u>> 0x1f
    v16_4:4.d = v7_4:4.d u>> 0x1f
    v16_4:8.d = v7_4:8.d u>> 0x1f
    v16_4:0xc.d = v7_4:0xc.d u>> 0x1f
    v7_4.d <<= 1
    v7_4:4.d <<= 1
    v7_4:8.d <<= 1
    v7_4:0xc.d <<= 1
    uint128_t v17_2
    v17_2.d = v6_5.d u>> 0x1e
    v17_2:4.d = v6_5:4.d u>> 0x1e
    v17_2:8.d = v6_5:8.d u>> 0x1e
    v17_2:0xc.d = v6_5:0xc.d u>> 0x1e
    v6_5.d <<= 2
    v6_5:4.d <<= 2
    v6_5:8.d <<= 2
    v6_5:0xc.d <<= 2
    uint128_t v7_5 = vorrq_s8(v7_4, v16_4)
    v16_4.d = v4_5.d u>> 0x1b
    v16_4:4.d = v4_5:4.d u>> 0x1b
    v16_4:8.d = v4_5:8.d u>> 0x1b
    v16_4:0xc.d = v4_5:0xc.d u>> 0x1b
    v4_5.d <<= 5
    v4_5:4.d <<= 5
    v4_5:8.d <<= 5
    v4_5:0xc.d <<= 5
    uint32_t x10_1 = zx.d(*(Botan::Noekeon::RC + i_1))
    uint128_t v6_6 = vorrq_s8(v6_5, v17_2)
    uint128_t v4_6 = vorrq_s8(v4_5, v16_4)
    uint128_t v7_6 = vorrq_s8(v4_6, v6_6) ^ v7_5
    v19.d = x10_1
    v19:4.d = x10_1
    v19:8.d = x10_1
    v19:0xc.d = x10_1
    uint128_t v5_5 = v4_6 ^ v6_6 ^ not.o(v7_6)
    uint128_t v4_9 = v5_4 ^ (v4_6 & not.o(v7_6)) ^ v19
    uint128_t v16_7 = v5_5 ^ v4_9
    v17.d = v4_9.d u>> 2
    v17:4.d = v4_9:4.d u>> 2
    v17:8.d = v4_9:8.d u>> 2
    v17:0xc.d = v4_9:0xc.d u>> 2
    v18.d = v4_9.d << 0x1e
    v18:4.d = v4_9:4.d << 0x1e
    v18:8.d = v4_9:8.d << 0x1e
    v18:0xc.d = v4_9:0xc.d << 0x1e
    uint128_t v4_10 = vorrq_s8(v5_5, v4_9) ^ v7_6
    uint128_t v5_6
    v5_6.d = v16_7.d u>> 5
    v5_6:4.d = v16_7:4.d u>> 5
    v5_6:8.d = v16_7:8.d u>> 5
    v5_6:0xc.d = v16_7:0xc.d u>> 5
    v7_6.d = v16_7.d << 0x1b
    v7_6:4.d = v16_7:4.d << 0x1b
    v7_6:8.d = v16_7:8.d << 0x1b
    v7_6:0xc.d = v16_7:0xc.d << 0x1b
    v19.d = v4_10.d u>> 1
    v19:4.d = v4_10:4.d u>> 1
    v19:8.d = v4_10:8.d u>> 1
    v19:0xc.d = v4_10:0xc.d u>> 1
    v20.d = v4_10.d << 0x1f
    v20:4.d = v4_10:4.d << 0x1f
    v20:8.d = v4_10:8.d << 0x1f
    v20:0xc.d = v4_10:0xc.d << 0x1f
    i = i_1
    i_1 -= 1
    v4_3 = vorrq_s8(v7_6, v5_6)
    v5_2 = (v4_10 & v16_7) ^ v6_6
    v7_2 = vorrq_s8(v20, v19)
    v6_3 = vorrq_s8(v18, v17)
while (i != 1)
uint128_t v16_9 = v5_2 ^ v4_3
int128_t v3_1 = v7_2 ^ v3
int128_t v0_1 = v6_3 ^ v0
int128_t v2_1 = v5_2 ^ v2
v5_2.d = v16_9.d u>> 0x18
v5_2:4.d = v16_9:4.d u>> 0x18
v5_2:8.d = v16_9:8.d u>> 0x18
v5_2:0xc.d = v16_9:0xc.d u>> 0x18
v6_3.d = v16_9.d << 8
v6_3:4.d = v16_9:4.d << 8
v6_3:8.d = v16_9:8.d << 8
v6_3:0xc.d = v16_9:0xc.d << 8
v7_2.d = v16_9.d u>> 8
v7_2:4.d = v16_9:4.d u>> 8
v7_2:8.d = v16_9:8.d u>> 8
v7_2:0xc.d = v16_9:0xc.d u>> 8
v17.d = v16_9.d << 0x18
v17:4.d = v16_9:4.d << 0x18
v17:8.d = v16_9:8.d << 0x18
v17:0xc.d = v16_9:0xc.d << 0x18
int128_t v18_2 = v0_1 ^ v3_1
uint128_t v5_7 = vorrq_s8(v6_3, v5_2)
uint128_t v6_7 = vorrq_s8(v17, v7_2)
v7_2.d = v18_2.d u>> 0x18
v7_2:4.d = v18_2:4.d u>> 0x18
v7_2:8.d = v18_2:8.d u>> 0x18
v7_2:0xc.d = v18_2:0xc.d u>> 0x18
v17.d = v18_2.d << 8
v17:4.d = v18_2:4.d << 8
v17:8.d = v18_2:8.d << 8
v17:0xc.d = v18_2:0xc.d << 8
v19.d = v18_2.d u>> 8
v19:4.d = v18_2:4.d u>> 8
v19:8.d = v18_2:8.d u>> 8
v19:0xc.d = v18_2:0xc.d u>> 8
uint128_t v5_8 = v5_7 ^ v16_9
v16_9.d = v18_2.d << 0x18
v16_9:4.d = v18_2:4.d << 0x18
v16_9:8.d = v18_2:8.d << 0x18
v16_9:0xc.d = v18_2:0xc.d << 0x18
uint128_t v5_9 = v5_8 ^ v6_7
uint128_t v3_2 = v3_1 ^ v5_9
uint128_t v0_2 = v0_1 ^ v5_9
int128_t v5_10 = vorrq_s8(v17, v7_2) ^ v18_2 ^ vorrq_s8(v16_9, v19)
int128_t v1_1 = v4_3 ^ v1
v4_3.d = 0x80
v4_3:4.d = 0x80
v4_3:8.d = 0x80
v4_3:0xc.d = 0x80
uint128_t v1_2 = v1_1 ^ v5_10
uint128_t v2_3 = v2_1 ^ v5_10 ^ v4_3
uint128_t v5_11 = vzip1q_s32(v3_2, v0_2)
uint128_t v0_3 = vzip2q_s32(v3_2, v0_2)
uint128_t v3_3 = vzip1q_s32(v2_3, v1_2)
uint128_t v1_3 = vzip2q_s32(v2_3, v1_2)
uint128_t v2_4 = vzip1q_s32(v3_3, v5_11)
uint128_t v3_4 = vzip2q_s32(v3_3, v5_11)
uint128_t v4_11 = vzip1q_s32(v1_3, v0_3)
uint128_t v0_4 = vzip2q_s32(v1_3, v0_3)
uint128_t v1_4 = vrev32q_s8(v2_4)
uint128_t v2_5 = vrev32q_s8(v3_4)
uint128_t v3_5 = vrev32q_s8(v4_11)
uint128_t v0_5 = vrev32q_s8(v0_4)
uint128_t* entry_x2
*entry_x2 = v1_4
entry_x2[1] = v2_5
entry_x2[2] = v3_5
entry_x2[3] = v0_5
